{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-the-imageomics-guide","title":"Welcome to the Imageomics Guide!","text":"<p>This website hosts Imageomics-focused guides to FAIR (findable, accessible, interoperable, reusable) and reproducible workflows, documentation, and general best-practices for collaborative science. We aim to provide a helpful resource for scientists working in imageomics and related interdisciplinary fields.</p> <p>This guide houses the information needed to get started with and use Imageomics Institute resources readily available to all members. However, most of this guide is applicable to anyone working more broadly in the field of imageomics or adjacent fields of computer and data science, and it is tailored to help domain scientists bridging that gap.</p>"},{"location":"#highlights","title":"Highlights","text":"<p>There are many pages of useful information contained in this guide covering a range of topics from project management and workflows, to repositories and archives, to a glossary of imageomics-related terms for improved interdisciplinary communication.</p>"},{"location":"#just-starting-a-project","title":"Just starting a project?","text":"<p>Check out our guides to get your project off on the right foot!</p> <ul> <li> <p>The GitHub Repo Guide: This page reviews expected and suggested GitHub repository contents, as well as structural considerations.</p> </li> <li> <p>The Hugging Face Repo Guide: Analogous expected and suggested repository contents for Hugging Face repositories; there are notable differences from GitHub in both content and structure.</p> </li> <li> <p>FAIR Guide: Guide to producing FAIR digital products, from metadata collection through product documentation and publication. This builds on the content in both the GitHub and Hugging Face Repository Guides, providing checklists to ensure code, data, and model repositories are FAIR. The latter two closely follow our HF Templates.</p> </li> </ul>"},{"location":"#project-repo-up-whats-next","title":"Project repo up, what's next?","text":"<p>Check out our workflow guides for how to interact with your new repo:</p> <ul> <li> <p>The GitHub Workflow: This page mainly focuses on branching and the PR process.</p> </li> <li> <p>The Hugging Face Workflow: Analogous workflow directions for Hugging Face; there are notable differences from GitHub in how this process works practically, though the concept is the same.</p> </li> </ul>"},{"location":"#project-management-or-organization-got-you-down","title":"Project management or organization got you down?","text":"<p>Discover new tools to help:</p> <ul> <li> <p>Guide to GitHub Projects: This page focuses on GitHub's project management tool, Projects, which integrates issues and pull requests into a unified task board to keep tabs on how your project is progressing. Labels, milestones, and assignee tags provide improved organization, and allow for more focused views.</p> </li> <li> <p>Helpful Tools for your Workflow: Collection of useful tools to facilitate and improve workflows. Comments and recommendations encouraged!</p> </li> <li> <p>Virtual Environments: Summary of <code>conda</code> and <code>pip</code> environments: how to make, use, and share them.</p> </li> </ul>"},{"location":"#collaborative-infrastructure-we-use","title":"Collaborative Infrastructure We Use","text":"<ul> <li>GitHub<ul> <li>Imageomics Code Repositories, where we store our code (software + tools).</li> <li>GitHub's Docs<ul> <li>Repositories</li> <li>GitHub Projects</li> </ul> </li> </ul> </li> <li>Hugging Face<ul> <li>Imageomics Organization Page, where we store our datasets and models (and their metadata).</li> <li>Additionally, use Hugging Face Spaces to run demos of models and other projects.</li> <li>Hugging Face's Docs<ul> <li>Model Hub</li> <li>Datasets</li> </ul> </li> </ul> </li> </ul>"},{"location":"#collaborative-infrastructure-diagram","title":"Collaborative Infrastructure Diagram","text":""},{"location":"#imageomics-branding-logos","title":"Imageomics Branding (Logos)","text":"<p>We have two versions of the logo, a fish and a butterfly, which should be used for scientific posters, conference, workshop, and meeting marketing materials, etc. Choice of logo is based on user preference.</p> <p> </p>"},{"location":"#other-pages-of-note","title":"Other pages of note","text":"<ul> <li>Glossary for Imageomics: Collection of terms used in imageomics. The goal is to ensure all participating domains are represented, thus facilitating interdisciplinary communication. This is a group effort, please check it out and add terms you think should be there!</li> <li>Command Line Cheat Sheet: Collection of useful bash and git commands with some git tips.</li> </ul> <p>Questions, Comments, or Concerns?</p>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#imageomics-institute-principles-of-engagement","title":"Imageomics Institute Principles of Engagement","text":"<p>As members of the Imageomics community, we agree to maintain an environment where every participant feels welcome to be their true self and speak from the heart.</p> <p>To this end, we agree as individuals and as a group to:</p> <ul> <li>Listen to understand. When one person talks, others listen.</li> <li>Speak to be understood. We use lay terms and are patient with people who are not experts in our specific field. We are all learning, no matter who we are.</li> <li>Embrace \u201cYes and\u2026\u201d Focus on possibilities instead of obstacles. Be inclusive of other people\u2019s ideas. Honor divergence.</li> <li>Take space / make space. Those who tend to talk a lot are intentional about letting others talk first, while those who tend to hold back are intentional about contributing.</li> <li>Beware of blind spots. We do not know what we do not know. We are vigilant for differences among our experiences and positions.</li> <li>Respect time. When a session is over, we need to move on. There is designated time for in-depth follow up and continuing conversations.</li> <li>Care for each other. We bring our full selves to the community, and we look out for each other wholeheartedly.</li> </ul> <p>AI use policy (borrowed from CRA):</p> <ul> <li>Allowable use of AI tools requires that the tools do not share or use the data for training.</li> <li>Requires permission if recording others. Language to use when requesting permission:</li> </ul> <p>\u201cWe would like to use <code>&lt;insert tool name here&gt;</code> during this discussion to assist with note-taking. <code>&lt;insert tool name here&gt;</code> records and transcribes audio and can produce a summary of the discussion. The audio and transcription will only be saved and used internally. Please let us know if you object to the use of <code>&lt;insert tool name here&gt;</code>.\u201d</p> <p>We abide by these principles in all Imageomics spaces, including but not limited to digital and in-person meetings, formal and informal gatherings, online discussion forums and chat spaces, and field and lab work.</p> <p>Acts of misconduct are prohibited. Those found to engage in misconduct will be subject to dismissal from the project and further actions as directed by the guidelines of the employers and the place of incidence.</p> <p>If you believe you have experienced or witnessed misconduct in an Imageomics setting, please take these steps:</p> <ol> <li>Document the incident;</li> <li>Tell someone you trust;</li> <li>Report the incident to Diane Boghrat.</li> </ol> <p>Privacy will be protected to the greatest extent possible.</p>"},{"location":"CODE_OF_CONDUCT/#values","title":"VALUES","text":""},{"location":"CODE_OF_CONDUCT/#transparency","title":"TRANSPARENCY","text":"<p>We ensure our efforts are clear about assumptions, uncertainty, and limits, and provide open sources of information, processes, and discovery.</p>"},{"location":"CODE_OF_CONDUCT/#accountability","title":"ACCOUNTABILITY","text":"<p>We are responsible, individually and collectively, for the outcomes we produce and ensure, to the best of our abilities, that the methods outcome matches intended use.</p>"},{"location":"CODE_OF_CONDUCT/#collaboration","title":"COLLABORATION","text":"<p>We create and nurture collaborative environments and welcome, value, and affirm all members of our community. We also consider how and for whom solutions are created and promote the heterogeneity of perspectives in the creation process. We actively engage others\u2019 perspectives, recognize everyone\u2019s potential to contribute new ideas, and work together to find creative solutions to complex problems.</p>"},{"location":"CODE_OF_CONDUCT/#safety","title":"SAFETY","text":"<p>We ensure our practices are ethical and impartial to the best of our ability. We address ethical issues when we discover them and practice good data governance.  We strive to enhance practices while openly addressing those that harm people or the environment.</p>"},{"location":"wiki-guide/About-Digital-Product-Policies/","title":"About Digital Product Policies","text":""},{"location":"wiki-guide/About-Digital-Product-Policies/#imageomics-digital-product-policies","title":"Imageomics Digital Product Policies","text":"<p>This section contains the Imageomics digital policy documents. The Digital Products Release and Licensing Policy sets expectations for the publication of all digital products (e.g., data, models, code). The Digital Product Life Cycle is a project life cycle guide intended to clarify the best practices\u2014described throughout this guide\u2014that will aid in compliance with the Digital Products Release and Licensing Policy. It is also generally a good reference for project planning.</p>"},{"location":"wiki-guide/About-Templates/","title":"About Templates","text":""},{"location":"wiki-guide/About-Templates/#using-dataset-and-model-card-templates","title":"Using Dataset and Model Card Templates","text":"<p>We provide Imageomics-specific Dataset and Model Card templates, adapted from Hugging Face's templates. These templates include guidance and examples for the various metadata sections, reference information for Hugging Face's particular flavor of markdown, and the appropriate NSF grant acknowledgment.</p> <p>To use a template for a new dataset or model repository on Hugging Face (HF), simply copy and paste the contents of the appropriate template (Dataset Card or Model Card) into your <code>README.md</code> file.<sup>1</sup> Then, follow the descriptions under each section to fill in the appropriate information. This is meant to be an iterative process throughout the life of your project, so do not worry if you cannot answer all parts at the beginning\u2014that's to be expected!</p> <p>Practice makes perfect!</p> <p>If you have never filled out a dataset card before, or are unsure of how to find the answers to fill in the sections, we ran a workshop to help familiarize our members with this process. In particular, the portion where we walked through filling out part of a dataset card as we did exploratory data analysis (EDA) was recorded and is available on the Imageomics YouTube Channel. Read the story of the workshop and clone the repo to follow along with the 1 hour and 15 minute lesson!</p> <p>Note</p> <p>The Dataset and Model cards have incorporated some of Hugging Face's January 2024 updates (following their Dataset Card Overhaul). It doesn't appear they will be updated more and we do not currently anticipate further large updates on our end as our overall template formats have diverged. Nevertheless, you may wish to check HF for extra information or tagging updates (HF Dataset Card, HF Model Card).</p> <ol> <li> <p>The templates can also be added to your repository thorugh the website user interface (UI): Navigate to the \"Model/Dataset Card\" tab on your repo, select \"Create Model/Dataset Card\", copy and paste the template contents into the <code>README.md</code> file, and add your content.\u00a0\u21a9</p> </li> </ol>"},{"location":"wiki-guide/Code-Checklist/","title":"Code Repo Checklist","text":""},{"location":"wiki-guide/Code-Checklist/#code-checklist","title":"Code Checklist","text":"<p>This checklist provides an overview of essential and recommended elements to include in a GitHub repository to ensure that it conforms to FAIR principles and best practices for reproducibility. Along with the generation of a DOI (see DOI Generation and Digital Products Release and Licensing Policy), following this checklist ensures compliance with the FAIR Principles for research software.<sup>1</sup></p> <p>Pro tip</p> <p>Use the eye icon at the top of this page to access the source and copy the markdown for the checklist below into an issue on your GitHub Repo or Project so you can check the boxes as you add each element to your GitHub repository.</p>"},{"location":"wiki-guide/Code-Checklist/#required-files","title":"Required Files","text":"<ul> <li> License: Verify and include an appropriate license (e.g., <code>MIT</code>, <code>CC0-1.0</code>, etc.). See discussion in the Repo Guide.</li> <li> README File: Following the Repo Guide, provide a detailed <code>README.md</code> with:<ul> <li> Overview of the project.</li> <li> Installation instructions.</li> <li> Basic usage examples.</li> <li> Links to related/created dataset(s).</li> <li> Links to related/created model(s).</li> <li> Acknowledge source code dependencies and contributors.</li> <li> Reference related datasets used in training or evaluation.</li> </ul> </li> <li> Requirements File: Provide a file detailing software requirements, such as a <code>requirements.txt</code> or <code>pyproject.toml</code> for Python dependencies.</li> <li> Gitignore File: GitHub has premade <code>.gitignore</code> files (see github/gitignore) tailored to particular languages (eg., R or Python), operating systems, etc.</li> <li> CITATION CFF: This facilitates citation of your work, follow guidance provided in the Repo Guide.</li> </ul>"},{"location":"wiki-guide/Code-Checklist/#data-related","title":"Data-Related","text":"<ul> <li> Preprocessing code.</li> <li> Description of dataset(s), including description of training and testing sets (with links to relevant portions of dataset card, which will have more information).</li> </ul>"},{"location":"wiki-guide/Code-Checklist/#model-related","title":"Model-Related","text":"<ul> <li> Training code.</li> <li> Inference/evaluation code.</li> <li> Model weights (if not in Hugging Face model repository).</li> <li> Description of model(s)/benchmark(s).</li> <li> Explanation of training and testing (with links to relevant portions of model card, which will have more information).</li> </ul> <p>Note</p> <p>The bioclip GitHub repository provides an example of incorporating data-and model-related code into a GitHub repository as published open-source code for both data and model development.</p>"},{"location":"wiki-guide/Code-Checklist/#general-information","title":"General Information","text":"<ul> <li> Repository Structure: Ensure the code repository follows a clear and logical directory structure. (See Repo Guide.)</li> <li> Code Comments: Include meaningful inline comments and function descriptions for clarity.</li> <li> Random Seed Control: Save seed(s) for random number generator(s) to ensure reproducible results.</li> </ul>"},{"location":"wiki-guide/Code-Checklist/#security-considerations","title":"Security Considerations","text":"<ul> <li> Sensitive Data Handling: Ensure no hardcoded sensitive information (e.g., API keys, credentials) are included in your repository. These can be shared through a config file on OSC.</li> </ul> <p>Note</p> <p>The best practices described below will help you meet the above requirements. The more advanced development practices noted further down are included for educational purposes and are highly recommended\u2014though these may go beyond what is expected for a given project, we advise collaborators to at least have a discussion about the topics covered in Code Quality and whether other practices discussed would be appropriate for their project.</p>"},{"location":"wiki-guide/Code-Checklist/#best-practices","title":"Best Practices","text":"<p>The Repo Guide provides general guidance on repository structure, collaborative workflow, and how to make and review pull requests (PR). Below, we highlight some best practices in checklist form to help you meet the requirements described above for a FAIR and Reproducible project.</p>"},{"location":"wiki-guide/Code-Checklist/#reproducibility","title":"Reproducibility","text":"<ul> <li>Version Control: Use Git for version control and commit regularly.</li> <li>Modularization: Structure code into reusable and independent modules.</li> <li>Code Execution: Provide Notebooks to demonstrate how to reproduce results.</li> </ul>"},{"location":"wiki-guide/Code-Checklist/#code-review-maintenance","title":"Code Review &amp; Maintenance","text":"<ul> <li>Code Reviews: Regular peer reviews for quality assurance. Refer to the GitHub PR Review Guide.</li> <li>Issue Tracking: Use GitHub issues for tracking bugs and feature requests.</li> <li>Versioning: Tag releases, changelogs can be auto-generated and informative when PRs are appropriately scoped.</li> </ul>"},{"location":"wiki-guide/Code-Checklist/#installation-and-dependencies","title":"Installation and Dependencies","text":"<ul> <li> Environment Setup: Include setup instructions (e.g., <code>conda</code> environment file, <code>Dockerfile</code>).</li> <li> Dependency Management: Use virtual environments and the frameworks that manage them (e.g., <code>venv</code>, <code>conda</code>, <code>uv</code> for Python) to isolate dependencies.</li> </ul>"},{"location":"wiki-guide/Code-Checklist/#more-advanced-development","title":"More Advanced Development","text":""},{"location":"wiki-guide/Code-Checklist/#documentation","title":"Documentation","text":"<ul> <li> API Documentation: Generate API documentation (e.g., <code>MkDocs</code> for Python or wiki pages in the repo).</li> <li> Docstrings: Add comprehensive docstrings for all functions, classes, and modules. These can be incorporated to help generate documentation. Note that generative AI tools with access to your code, such as GitHub Copilot, can be quite accurate in generating these, especially if you are using type annotations.</li> <li> Example Scripts: Include example scripts for common use cases.</li> <li> Configuration Files: Use <code>yaml</code>, <code>json</code>, or <code>ini</code> for configuration settings.</li> </ul>"},{"location":"wiki-guide/Code-Checklist/#code-quality","title":"Code Quality","text":"<ul> <li> Consistent Style: Follow coding style guidelines (e.g., <code>PEP 8</code> for Python).</li> <li> Linting: Ensure the code passes a linter (e.g., <code>Ruff</code> for Python).</li> <li> Logging: Use logging instead of print statements for better debugging (e.g., <code>logging</code> in Python).</li> <li> Error Handling: Implement robust exception handling to avoid crashes or bogus results from input outside of code expectations.</li> </ul>"},{"location":"wiki-guide/Code-Checklist/#testing","title":"Testing","text":"<ul> <li> Unit Tests: Write unit tests to validate core functionality.</li> <li> Integration Tests: Ensure components work together correctly.</li> <li> Test Coverage: Check test coverage, e.g., using Coverage.</li> <li> Continuous Integration (CI): Set up CI/CD pipelines (e.g., GitHub Actions) for automated testing.</li> </ul>"},{"location":"wiki-guide/Code-Checklist/#code-distribution-deployment","title":"Code Distribution &amp; Deployment","text":"<ul> <li> Packaging: Provide installation instructions (e.g., <code>setup.py</code>, <code>hatch</code>, <code>poetry</code>, <code>uv</code> for Python).</li> <li> Deployment Guide: Document deployment procedures</li> </ul> <p>Questions, Comments, or Concerns?</p> <ol> <li> <p>Barker, M., Chue Hong, N. P., Katz, D. S., Lamprecht, A. L., Martinez-Ortiz, C., Psomopoulos, F., Harrow, J., Castro, L. J., Gruenpeter, M., Martinez, P. A., &amp; Honeyman, T. (2022). Introducing the FAIR Principles for research software. Scientific data, 9(1), 622. URL.\u00a0\u21a9</p> </li> </ol>"},{"location":"wiki-guide/Command-Line-Cheat-Sheet/","title":"Command Line Cheat Sheet","text":""},{"location":"wiki-guide/Command-Line-Cheat-Sheet/#command-line-cheat-sheet","title":"Command Line Cheat Sheet","text":"<p>See also GitHub's Markdown Guide.</p>"},{"location":"wiki-guide/Command-Line-Cheat-Sheet/#useful-bash-and-git","title":"Useful bash and git","text":"Command Action <code>&lt;cmd&gt; -h</code> print the help documentation for a command, showing usage information and options <code>cd</code> change directory <code>cd ..</code> up one directory <code>pwd</code> current working directory <code>ls</code> list everything in current directory (use <code>-a</code> to also show all files including hidden, <code>-l</code> for a long list including permissions and ownership info, <code>-1</code> (\"dash one\") to display the output with 1 item on each line) <code>wc -l &lt;file&gt;</code> use the word count command with the <code>-l</code> lines option to list the number of lines in a file <code>du &lt;dirname&gt;/</code> calculate and show how much disk usage is consumed by a directory (use <code>-h</code> to make it human-readable, i.e. report in MB, GB or whatever units are most appropriate, and <code>-s</code> for summary of all the contents together rather than each item individually) Ctrl+R search for command (will pop up <code>bck-i-search:</code>) <code>rm &lt;target&gt;</code> remove a file (or folder with <code>-r</code>). Beware when using <code>rm -rf &lt;folder&gt;</code> to force the recursive removal of all contents in a folder, which cannot be undone unless there is a backup. <code>&lt;cmd1&gt; | &lt;cmd2&gt;</code> The \"pipe\" operator (|) feeds the output of the first command (<code>cmd1</code>) to the input of the second command (<code>cmd2</code>). For example, show the total number of files in a directory with <code>ls -1 &lt;dir&gt; | wc -l</code>"},{"location":"wiki-guide/Command-Line-Cheat-Sheet/#git-specific","title":"Git-Specific","text":"Command Action <code>git log</code> list of commits with author, date, time (type <code>q</code> to leave) <code>git log --oneline</code> list of just commits (ID, location, message), type <code>q</code> to leave <code>git status</code> status of local vs remote repo (commits, ignored files, etc),  shows changed files that git is tracking and that git is not tracking <code>git rm &lt;target&gt;</code> remove file (or folder with <code>-r</code>) from repo and filesystem (or just from the repo and not filesystem with <code>--cached</code>) cache file ex: <code>git rm -r --cached __pycache__</code> <code>git mv &lt;file&gt; &lt;folder&gt;</code> move file to folder or rename: <code>git mv &lt;filename&gt; &lt;new_filename&gt;</code> <code>git branch</code> list branches, current branch has <code>*</code> in front and is green <code>git checkout -b &lt;branch&gt;</code> create new branch and check it out <code>git checkout &lt;branch&gt;</code> checkout branch <code>git branch -d &lt;branch&gt;</code> delete branch <p>Pro tip: Simplify your git history</p> <ul> <li>Use <code>git mv</code> to rename a file so that it is tracked as a rename (with or without changes).</li> <li>If you rename a file then <code>git add</code> its parent directory, the diff will show the deletion of the original file and addition of a \"completely new\" file, even if nothing has changed. This makes reviewing changes much more complicated than necessary.</li> </ul>"},{"location":"wiki-guide/Command-Line-Cheat-Sheet/#usual-process","title":"Usual Process","text":"<p>After making changes to a file on a branch, check the status of your current working branch (with <code>git status</code>). Then, you \"add\" the file, state what is new about the file (\"commit the change\"), and <code>push</code> the file from your local copy of the repo to the remote copy:</p> <pre><code>git add &lt;filename&gt;\n\ngit commit -m \"Changed x,y,z\"\n\ngit push\n</code></pre> <p>Pro tip: Check the stage</p> <p>After using <code>git add &lt;folder&gt;</code> or <code>git add &lt;regex&gt;</code> (a pattern match), run <code>git status</code> to ensure that all intended files--and only intended files--are staged for commit.</p> <p>Note</p> <p>If you need to update your branch with changes from the remote <code>main</code>, first switch to the branch, then set pull from <code>main</code> instead of the current branch, as below.</p> <pre><code>git checkout &lt;branch&gt;       \n\ngit pull origin main\n</code></pre>"},{"location":"wiki-guide/DOI-Generation/","title":"DOI Generation","text":""},{"location":"wiki-guide/DOI-Generation/#doi-generation","title":"DOI Generation","text":"<p>This guide discusses DOI generation for digital artifacts that may be associated with publications, such as datasets, models, and software. You are likely familiar with DOIs from citing (journal/arXiv/conference) papers, for which they are generated by the publisher and regularly used in citations. However, they are also invaluable for proper citation of code, models, and data. Similar to how DOIs help track different versions of preprints on repositories like arXiv, they can provide persistent identification and versioning for your research artifacts beyond traditional publications.</p>"},{"location":"wiki-guide/DOI-Generation/#what-is-a-doi","title":"What is a DOI?","text":"<p>A DOI (Digital Object Identifier) is a persistent (permanent) digital identifier for any object (data, model, code, etc.) that uniquely distinguishes it from other objects and links to information\u2014metadata\u2014about the object. The International DOI Foundation (IDF) is responsible for developing and administering the DOI system. See their What is a DOI? article for more information.</p>"},{"location":"wiki-guide/DOI-Generation/#how-do-you-generate-a-doi","title":"How do you generate a DOI?","text":"<p>When publishing code, data, or models, there are various options for DOI generation, and selecting one is generally dependent on where the object of interest is published. We will go over the two standard methods used by the Institute here, and we mention a third option for completeness. A comparison of these three options is provided in the Data Archive Options Comparative Overview.</p>"},{"location":"wiki-guide/DOI-Generation/#1-generate-a-doi-on-hugging-face","title":"1. Generate a DOI on Hugging Face","text":"<p>This is the simplest method for generating a DOI for a model or dataset since Hugging Face partnered with DataCite to offer this option.</p> <p>Warning</p> <p>Though it is a very simple process, it is not one to be taken lightly, as there is no removing data once this has been done--any changes require generation of a new DOI for the updated version: the old version will be maintained in perpetuity!</p> <p>Warning</p> <p>As stated in the Imageomics Digital Products Release and Licensing Policy, DOIs are not to be generated for Imageomics Organization Repositories until approval has been granted by the Senior Data Scientist or Institute Leadership.</p> <p>Hugging Face allows for the generation of a DOI through the settings tab on the Model or Dataset. For details on how to generate a DOI with Hugging Face, please see the Hugging Face DOI Documentation.</p>"},{"location":"wiki-guide/DOI-Generation/#2-generate-a-doi-with-zenodo","title":"2. Generate a DOI with Zenodo","text":"<p>This is the most common method used for generating a DOI for a GitHub repository, because Zenodo has a GitHub integration, which is accessed through your Zenodo account settings (for more information, please see GitHub's associated Docs). Zenodo can also be used to generate DOIs for data, as is relatively common in biology. However, for direct use of ML models and datasets, there are many more advantages to using Hugging Face; please see the Data Archive Options Comparative Overview for more information.<sup>1</sup></p>"},{"location":"wiki-guide/DOI-Generation/#automatic-generation","title":"Automatic Generation","text":"<p>When your GitHub and Zenodo accounts are linked, there will be a list of available repositories under the GitHub tab in settings on Zenodo. All those that are enabled are grouped at the top (just below the instructions). If the switch is on to enable a repository, then your next GitHub release will trigger the generation of a repository snapshot with a new or updated DOI. Click on the DOI badge next to the repository to get the code to add the badge to your repository README. Clicking on the repository name will take you to information about that repository's releases.</p> <p></p> <p>The Sync now button</p> <p>There is a \"Sync now\" button at the top right of the instructions, with information on when the last sync occurred. Observe that a badge appears for the enabled repository that has a DOI, while the one without just shows up as enabled; this will also be true for repositories to which you have access but that you did not submit to Zenodo yourself.</p>"},{"location":"wiki-guide/DOI-Generation/#metadata-tracking","title":"Metadata Tracking","text":"<p>When automatically generating a DOI with Zenodo, it uses information provided in your <code>CITATION.cff</code> file to populate the metadata for the record. However, there is important information that is not supported through this integration despite its inclusion in the <code>CITATION.cff</code> format in some cases.</p> <p>If your repository is likely to be updated repeatedly (i.e., generating new releases), then you may consider adding a <code>.zenodo.json</code> to preserve the remaining metadata on release sync with Zenodo for DOI. This metadata includes grant (funding) information, references (which may be included in your <code>CITATION.cff</code>), associated paper(s), and a description of your repository/code. Details and a sample file structure are provided in the Zenodo Metadata section of the GitHub Repo Guide.</p> <p>Alternatively, this information can be updated manually on the Zenodo page for the DOI record. When logged in to Zenodo, a large orange \"Edit\" button will appear in the top right (as in the image below). There is the ability to save as you go (without publishing the metadata changes) and an additional option to share a link with collaborators to view the suggested record information.</p> <p></p> <p>Note</p> <p>Each collaborator who should have access to the Zenodo record must be manually granted access through their Zenodo account. This can be done by clicking on the \"Share\" button and selecting \"Add people\" at the pop-up screen.</p> <p>It is highly recommended that at least one other person on a project has access at the \"manage\" level.</p>"},{"location":"wiki-guide/DOI-Generation/#manual-generation","title":"Manual Generation","text":"<p>Building on the alternate edit options, there is also the option to simply generate one or all of your releases through a direct upload to Zenodo's site. Automatic generation through the GitHub integration is the recommended approach since it will generate an updated DOI on each release and create easier connections.</p> <p>Warning</p> <p>Do not mix the two methods. One must start with the GitHub integration, otherwise two separate records will be created. If a repo already has releases prior to turning on the GitHub integration, one can contact Zenodo to have them import the earlier releases as well. This is also another motivator for setting up the requisite files in a GitHub repo before the first release.</p>"},{"location":"wiki-guide/DOI-Generation/#access-management","title":"Access Management","text":"<p>When creating a new record on Zenodo, please ensure that other members of your project have access, as appropriate. In particular, there should be at least one member of Institute leadership or the Senior Data Scientist added to the record with management permissions. This ensures the ability to maintain the metadata and address matters related to the record (which may extend beyond your tenure with the Institute) in a timely manner.</p>"},{"location":"wiki-guide/DOI-Generation/#add-a-zenodo-doi-badge","title":"Add a Zenodo DOI Badge","text":"<p>Congratulations, your repository has been archived on Zenodo! Now, how do you get the nice badge to display on your GitHub <code>README</code> so everyone knows it has been archived?</p> <ol> <li> <p>Navigate to your account settings and select \"GitHub\" (see earlier screenshot at automatic generation for what the page looks like).</p> </li> <li> <p>Find the repo that has just been updated in the \"Enabled Repositories\" list (we'll use this guide's repo for the example), and click on the badge next to the repo's name:</p> <p></p> <p>The pop up will look something like this:</p> <p></p> </li> <li> <p>Copy the Markdown text and paste it next to your <code>README</code> title. Note that the DOI URL should be the version agnostic DOI (this is the one you will add to your <code>CITATION.cff</code>, as noted in the GitHub Repo Guide)</p> <p></p> </li> </ol> <p>This only has to be done once; using the version agnostic DOI with the general SVG means the badge will be updated to always display the DOI of the latest release and it will link to that Zenodo record.</p> <p>Warning</p> <p>If you use the badge from the Zenodo page itself, it will be specific for that version, so be sure to get the version agnostic one.</p>"},{"location":"wiki-guide/DOI-Generation/#3-generate-a-doi-with-dryad","title":"3. Generate a DOI with Dryad","text":"<p>Dryad is another research data repository, similar to Zenodo, through which one can archive digital objects (such as, but not limited to, data) supporting scholarly publications, and obtain a DOI. It has a review process when depositing data and requires dedication to the public domain (CC0) of all digital objects uploaded. Imageomics through OSU is a member organization of Dryad, reducing or eliminating data deposit charge(s). To determine whether Dryad is a suitable archive for Institute data products supporting your publication, please consider the Data Archive Options Comparative Overview for more information, and consult with the Institute's Senior Data Scientist.<sup>1</sup></p> <p>Questions, Comments, or Concerns?</p> <ol> <li> <p>The Data Archive Options Comparative Overview was created in May 2023 when we were deciding Institute archive recommendations, so it does not include information about newer features such as Hugging Face's dataset viewer, which greatly simplifies previewing datasets for downstream users.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"wiki-guide/Data-Checklist/","title":"Data Card Checklist","text":""},{"location":"wiki-guide/Data-Checklist/#dataset-card-checklist","title":"Dataset Card Checklist","text":"<p>Below is a checklist encompassing all sections of a dataset card. Review notes and guidance provided in the full dataset card template for more details.</p> <p>Pro tip</p> <p>Use the eye icon at the top of this page to access the source and copy the markdown for the checklist below into an issue on your GitHub Repo or Project so you can check the boxes as you add each element to your dataset card.</p>"},{"location":"wiki-guide/Data-Checklist/#general-information","title":"General Information","text":"<ul> <li> License: Verify and specify the license type (e.g., <code>cc0-1.0</code>).</li> <li> Language: Indicate the language(s) (e.g., <code>en</code>).</li> <li> Pretty Name: Provide a descriptive name for the dataset.</li> <li> Task Categories: List relevant task categories (e.g., image-classification). Refer to the coarse-grained taxonomy of task categories as well as subtasks in this file.</li> <li> Tags: Include relevant tags (e.g., <code>biology</code>, <code>image</code>, <code>animals</code>, <code>CV</code>).</li> <li> Size Categories: Specify dataset size (e.g., <code>n&lt;1k</code>, <code>1k&lt;n&lt;10k</code>, etc.).</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#dataset-details","title":"Dataset Details","text":"<ul> <li> Curated by: List curators or authors.</li> <li> Language(s) (NLP): Specify if applicable.</li> <li> Homepage: Provide a link to the homepage (if you have a website set up, not required).</li> <li> Repository: Link to related GitHub repository.</li> <li> Paper: Link to related research paper (not expected at this point).</li> <li> Description: Provide a summary of what the dataset is used for.</li> <li> Supported Tasks and Leaderboards: List any relevant tasks and leaderboards, e.g., benchmarking results.</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#dataset-structure","title":"Dataset Structure","text":"<ul> <li> Data Format: Describe the structure of the dataset. See guidance on formatting in the full dataset card template.</li> <li> Data Instances: Describe data files. E.g.: All images are named <code>&lt;img_id&gt;.png</code>, each within a folder named for the species. They are 1024 x 1024, and the color has been standardized using <code>&lt;link to color standardization package&gt;</code>.</li> <li> Data Fields: Describe the types of the data files or the columns in a CSV with metadata (example).</li> <li> Data Splits: Describe any splits (e.g., train, test, validation).</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#dataset-creation","title":"Dataset Creation","text":"<p>Refer to examples and explanations provided in the full dataset card template.</p> <ul> <li> Curation Rationale: Explain why this dataset was created.</li> <li> Source Data: Describe the source data.<ul> <li> Data Collection and Processing: Describe data creation, selection, filtering, normalization, and tools used.</li> <li> Source Data Producers: List original data producers or sources.</li> </ul> </li> <li> Annotations: Include details on annotations.<ul> <li> Annotation Process: Describe the process and tools used.</li> <li> Annotators: List the annotators if applicable.</li> </ul> </li> <li> Personal and Sensitive Information: Indicate any sensitive information in the dataset.</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#considerations-for-using-the-data","title":"Considerations for Using the Data","text":"<p>There are several things to consider while working with the dataset that should be reported to users. For instance, maybe there are hybrids and they are labeled in the <code>hybrid_stat</code> column, so to get a subset without hybrids, subset to all instances in the metadata file such that <code>hybrid_stat</code> is not \"hybrid\".</p> <ul> <li> Bias, Risks, and Limitations: Describe any known issues with the dataset. For instance, if your data exhibits a long-tailed distribution (and why).</li> <li> Recommendations: Provide recommendations for using the dataset responsibly.</li> <li> Reporting issues: Provide a link to the issue tracker or other mechanism for reporting problems (e.g. mislabeling, corrupted images, etc.). This can simply be the Community tab for the repository or Issues on the associated GitHub repository.</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#licensing-information","title":"Licensing Information","text":"<p>See discussion and references in the template, also remember the digital product release and licensing policy.</p> <ul> <li> Licensing Details: Confirm and list all licensing details.</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#citation","title":"Citation","text":"<ul> <li> Data Citation: Provide a BibTeX citation for the dataset.</li> <li> Associated Paper Citation: Provide a BibTeX citation for any associated papers.</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#acknowledgements","title":"Acknowledgements","text":"<ul> <li> Acknowledgements: Include funding or support acknowledgments.</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#glossary-optional","title":"Glossary (Optional)","text":"<ul> <li> Glossary: Provide definitions for relevant terms or calculations.</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#more-information-optional","title":"More Information (Optional)","text":"<ul> <li> Additional Information: Add any other relevant information.</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#dataset-card-authors","title":"Dataset Card Authors","text":"<ul> <li> Authors: List the authors of the dataset card.</li> </ul>"},{"location":"wiki-guide/Data-Checklist/#dataset-card-contact","title":"Dataset Card Contact","text":"<ul> <li> Contact Information: [OPTIONAL] We recommend people use HF discussions, but you may indicate a person to contact.</li> </ul> <p>Questions, Comments, or Concerns?</p>"},{"location":"wiki-guide/Digital-Product-Lifecycle/","title":"Digital Product Life Cycle","text":""},{"location":"wiki-guide/Digital-Product-Lifecycle/#digital-product-life-cycle","title":"Digital Product Life Cycle","text":"<p>The Imageomics Institute is committed to FAIR and Reproducible data, software, ML models, and computational workflows, as demonstrated and defined by the Digital Products Release and Licensing Policy that the Institute adopted. To achieve full and consistent adherence to this policy, promote integration of requisite best practices into the research project lifecycle, and to ensure the limited data science support resources of the Institute for assistance are utilized efficiently, the Digital Product Life Cycle aims to establish a life cycle framework with designated, regular, interspersed points at which research project teams are expected to engage with the Institute\u2019s data science support team about digital artifacts and practices supporting adherence to our digital product commitments.</p> <p>Although most of the engagement from the side of research teams is expected to (and arguably should) primarily involve NextGens, responsibility for awareness of this policy and a team\u2019s commitment to follow it lies with project<sup>1</sup> PI(s). By following these guidelines, it will be easier to meet these requirements before paper submission deadlines without requiring major revisions on a truncated schedule (i.e., most\u2014if not all\u2014of the FAIR requirements will have been resolved prior to conference submissions). Below is a project life cycle diagram outlining the expected process of this policy, followed by an enumeration of the expectations organized by development phase.</p> <p> Figure 1: Visual representation of the AI/ML project life cycle underpinning this policy. After the Setup phase, both Exploration and Model Development are ongoing iterative processes that build to the ultimate goal of a published paper, following Publication Preparation where the work of the previous iterative phases is reviewed and polished for Findability, Accessibility Interoperability, Reusability (FAIR) and Reproducibility. Key Stages for Project Consultations are highlighted, along with Helpful Resources to guide work at each stage and checklists to ensure FAIR and Reproducibility are always in mind.</p>"},{"location":"wiki-guide/Digital-Product-Lifecycle/#responsibilities-and-actions","title":"Responsibilities and Actions","text":"<p>The following adds additional context and direction to supplement the diagram, organized by project lifecycle stage.</p>"},{"location":"wiki-guide/Digital-Product-Lifecycle/#setup-phase","title":"Setup Phase","text":"<ul> <li>NextGens and/or project<sup>1</sup> PIs schedule a project consultation with the Senior Data Scientist. This will include scope and intended data usage for improved research convergence and to ensure projects start with all available resources in mind.</li> <li>In GitHub project repo, create an issue for each of the repositories for the digital products with the appropriate checklist:<ul> <li>Code and workflows: GitHub Repository (Code checklist).</li> <li>Datasets: Hugging Face Dataset Repository (Data checklist).<ul> <li>For already published data usage, see the Metadata Checklist.</li> </ul> </li> <li>ML Models: Hugging Face Model Repository (Model checklist).</li> </ul> </li> </ul>"},{"location":"wiki-guide/Digital-Product-Lifecycle/#exploration-phase","title":"Exploration Phase","text":"<ul> <li>Maintain record of any and all data utilized (source, license, citation, etc.).<ul> <li>See Data Sources Template.</li> </ul> </li> <li>Document exploration of data.<ul> <li>This establishes an understanding of what the data is and how it can be used. For an example and guidance, consider the exploration and documentation done in the Data Workshop.</li> </ul> </li> <li>Record processing steps applied\u2014maintained in a well-documented code repository (following GitHub Guidance)\u2014and update Dataset Card(s) with information and links back to GitHub repository.</li> <li>Establish and update contributor list\u2014follow the Imageomics Author Guide.<sup>2</sup><ul> <li>Authors and author order for the paper and codebase (and/or dataset) may differ, all should be discussed.</li> </ul> </li> </ul>"},{"location":"wiki-guide/Digital-Product-Lifecycle/#model-development-phase","title":"Model Development Phase","text":"<ul> <li>Maintain a record of any and all base models utilized (source, license, citation, etc.).</li> <li>Record model experiments\u2014scripts or Jupyter Notebooks, documented<sup>3</sup> and maintained in GitHub for version control as different approaches are tried.</li> <li>Document model experiments and evaluation\u2014record results of various tests performed and overall evaluation and comparison of these runs in Model Card(s) with links back to GitHub repository.</li> <li>Add all code used to generate figures to the project GitHub repository; including documentation for reproduction (e.g., package requirements, data info, instructions).</li> <li>Review (and revise as necessary) the Author/Contributor list(s).</li> </ul>"},{"location":"wiki-guide/Digital-Product-Lifecycle/#preparing-for-publication-phase","title":"Preparing for Publication Phase","text":"<ul> <li>Project components should align with FAIR and Reproducibility principles:<ul> <li>Completed and fully documented GitHub Repository for code (recall Code checklist).</li> <li>Completed and fully documented Hugging Face Dataset Repository for data products (recall Data checklist).<ul> <li>If using an already published dataset, all requisite metadata and provenance information included (recall Metadata checklist). Specifically, ensure that all attribution requirements and/or expectations have been appropriately met.</li> </ul> </li> <li>Completed and fully documented Hugging Face Model Repository for ML models (recall Model checklist).</li> </ul> </li> <li>Schedule Review by Senior Data Scientist of data, model, and code repositories 3 weeks prior to camera-ready deadline (approval required for DOI generation).</li> <li>Review (and revise as necessary) the Author/Contributor list(s).</li> </ul> <ol> <li> <p>Here we use the term project at a smaller scale to mean any endeavor resulting in a digital product (dataset, ML model, code) and/or paper (e.g., for the purposes of this policy SST is a project, while Butterflies is not).\u00a0\u21a9\u21a9</p> </li> <li> <p>Contributor lists should be started as early as possible and are subject to change as a project progresses; this is expected and the reason to review during each phase of development.\u00a0\u21a9</p> </li> <li> <p>Notebooks allow for Markdown explanations and descriptions throughout your process and the demonstration of results without requiring others to run your code.\u00a0\u21a9</p> </li> </ol>"},{"location":"wiki-guide/Digital-products-release-licensing-policy/","title":"Release and Licensing Policy","text":""},{"location":"wiki-guide/Digital-products-release-licensing-policy/#digital-products-release-and-licensing-policy","title":"Digital Products Release and Licensing Policy","text":"<p>To further the goals and motivations of the NSF grant supporting the Imageomics Institute, and to fulfill the requirements from the Data Management Plan (DMP) associated with the grant, all data, model, and code products generated or augmented under the auspices and support of the Institute should adhere to FAIR principles. Datasets that include Indigenous data should also adhere to CARE principles.</p> <p>This means the following policy applies for digital products of the Imageomics Institute:</p> <ol> <li> <p>All digital products (code, data, models, documentation, tutorials, etc) are to be released such that they are accessible to the public, at the latest by the time of associated paper publication, under an Open Content license or terms of use.</p> <ul> <li>Educational materials are outside of the scope of this policy, but are encouraged to follow these guidelines nonetheless.</li> </ul> </li> <li> <p>Code is to be released under an OSI-approved open source license, or to the public domain (for example, by applying a CC-Zero waiver).</p> <ul> <li> <p>This should be in a well-documented GitHub repository that follows the format specified in the Institute GitHub Repo Guide.</p> </li> <li> <p>If associated with a publication, code should be versioned with a release linked to a DOI that can be referenced in the publication.</p> </li> </ul> </li> <li> <p>Data, documents, tutorials, etc are to be released either to the public domain (for example, by applying a CC-Zero waiver), or under terms no more restrictive than requiring attribution (such as CC-BY).</p> <ul> <li> <p>For image and video datasets, this only applies to items that are not already licensed by (and thus used under license from) a third party.</p> </li> <li> <p>For datasets that include Indigenous data, see Carroll et al (2020) and Carroll et al (2021) for reconciling FAIR and CARE principles for scientific data.</p> </li> <li> <p>Datasets collected in whole or in part from regions that harbor Indigenous researchers are to at least adhere to the Collective Benefit principle (the C in CARE), even if they have been expressly released from or are otherwise entirely unencumbered by Indigenous rights. Specifically, at a minimum they are to be made available to respective Indigenous researchers with the least obstacles possible.</p> </li> <li> <p>For ML-ready datasets, for storage, version control, and sharing we recommend using Hugging Face Dataset Hub, which provides for rich metadata description in the form of a Dataset Card. (See Imageomics datasets published there as examples.)</p> </li> <li> <p>Refer to the Imageomics Hugging Face and FAIR guides for best-practices and further guidance.</p> </li> </ul> </li> <li> <p>ML models are to be released under an OSI-approved open source license or to the public domain (for example, by applying a CC-Zero waiver). In the case of potentially sensitive models or data (e.g., endangered species information), an Open Responsible AI License (Open RAIL-M) may be considered.</p> <ul> <li> <p>For further guidance, consider the chapter on Machine Learning Model Licenses from The Turing Way.</p> </li> <li> <p>For storage, version control, sharing, and publishing (including DOI provision), we recommend using Hugging Face Model Hub, which provides for rich metadata description in the form of a Model Card. (See Imageomics models published there as examples.)</p> </li> <li> <p>Refer to the Imageomics Hugging Face Guide for best-practices and further guidance.</p> </li> </ul> </li> <li> <p>All code, data, and models published on the Imageomics Organization (GitHub or Hugging Face) must be reviewed and approved by the Senior Data Scientist or Institute leadership prior to DOI generation.</p> <ul> <li>Further guidance and resources to best adhere to Institute standards can be found in the Imageomics Guide.</li> </ul> </li> </ol>"},{"location":"wiki-guide/FAIR-Guide/","title":"About FAIR Principles","text":""},{"location":"wiki-guide/FAIR-Guide/#fair-guide","title":"FAIR Guide","text":"<p>This section provides information and resources to help ensure that digital products are Findable, Accessible, Interoperable, Reusable, and Reproducible<sup>1</sup>. A general Metadata Checklist is provided to stimulate thinking about the type of information to be collected. Additionally, we include checklists for code, data, and model repositories. The code checklist focuses on the contents of a well-documented GitHub repository, while the data and model checklists cover the content of the data and model card templates, respectively.</p> <p>Each checklist was developed following the FAIR principles (as defined by the Go-FAIR Initiative). They provide a detailed outline of tasks and files to include to ensure alignment with the FAIR principles, and are complementary to the descriptions provided within the GitHub and Hugging Face Guides presented on this site. As with the contents of these Guides, these checklists are based on a combination of existing guides (e.g., The Turing Way, the Model Card Guidebook, and the Dataset Card Creation Guide) and the experiences of our team. Following these checklists ensures digital products are aligned with FAIR principles and a best-effort toward reproducibility.<sup>2</sup></p> <p>Pro tip</p> <p>Use the eye icon at the top of any checklist page to access the source and copy the markdown for the checklist into an issue on your GitHub Repo or Project so you can check the boxes as you add each. When added to the main description of the issue, the issue summary will show x out of total components completed for that issue.</p> <p>The last topic in this section discusses different methods of DOI Generation for digital products (code, data, and models). It focuses on our selected method for dataset publication: Hugging Face, with some guidance on using Zenodo to archive code (specifically, a GitHub repository). For more information about other common data publication venues\u2014and to see the thought process behind our selection\u2014see the Data Archive Options Comparative Overview for more information.<sup>3</sup> Generating a DOI for a digital product is part of ensuring a globally unique and persistent identifier that can be used to reference and refer back to a digital product\u2014an important component of FAIR and Reproducible principles.</p> <p>References and Background</p> <p>If you want to learn more about FAIR and Reproducible principles, explore these resources that we used when developing this guide:</p> <ul> <li> <p>The Turing Way: an open-source, community data science handbook. It provides a strong foundation on the guiding principles for this Guide, providing accessible explanations and overviews of topics from reproducibility, to collaboration and communication, to project design, to ethical research. </p> <p>This is a particularly good resource for those just starting to use <code>git</code> and GitHub. It builds motivation for use of version control through the lens of reproducibility.</p> </li> <li> <p>Go-FAIR Initiative: The FAIR Principles</p> </li> <li> <p>Ozoani, Ezi and Gerchick, Marissa and Mitchell, Margaret. Model Card Guidebook. Hugging Face, 2022. https://huggingface.co/docs/hub/en/model-card-guidebook. </p> <p>The authors also provide a nice summary of related work, including Datasheets for Datasets (Gebru, et al., 2018) and The Dataset Nutrition Label (label, paper).</p> </li> <li> <p>Wilkinson, M., Dumontier, M., Aalbersberg, I. et al. The FAIR Guiding Principles for scientific data management and stewardship. Sci Data 3, 160018 (2016). 10.1038/sdata.2016.18</p> </li> <li>Barker, M., Chue Hong, N.P., Katz, D.S. et al. Introducing the FAIR Principles for research software. Sci Data 9, 622 (2022). 10.1038/s41597-022-01710-x</li> <li>Balk, M. A., Bradley, J., Maruf, M., Altinta\u015f, B., Baki\u015f, Y., Bart, H. L. Jr, Breen, D., Florian, C. R., Greenberg, J., Karpatne, A., Karnani, K., Mabee, P., Pepper, J., Jebbia, D., Tabarin, T., Wang, X., &amp; Lapp, H. (2024). A FAIR and modular image-based workflow for knowledge discovery in the emerging field of imageomics. Methods in Ecology and Evolution, 15, 1129\u20131145. 10.1111/2041-210X.14327</li> <li>The FARR Research Coordination Network has a number of interesting resources and events.</li> <li>The Research Data Aliance for Interdisciplinary Research also provides links to resources and events particularly focused on considerations in interdisciplinary research.</li> </ul> <p>Questions, Comments, or Concerns?</p> <ol> <li> <p>While \"Reproducible\" is not part of the original FAIR principles as defined by the Go-FAIR Initiative, we include it here to emphasize the importance of computational reproducibility alongside data stewardship. This extension reflects emerging practice in data-intensive science, where code, models, and workflows must be reusable and verifiable to support robust scientific claims. It is not part of the formal FAIR acronym, but aligns with broader community goals for open and transparent research.\u00a0\u21a9</p> </li> <li> <p>Full reproducibility is difficult to achieve; this presentation by Odd Erik Gundersen provides a discussion of the varying degrees of reproducibilityand useful references when considering the level of reproducibility achieved by a given project.\u00a0\u21a9</p> </li> <li> <p>The Data Archive Options Comparative Overview was created in May 2023 as part of developing archive recommendations for the Institute, so it does not include information about newer features such as Hugging Face's dataset viewer, which greatly simplifies previewing datasets for downstream users.\u00a0\u21a9</p> </li> </ol>"},{"location":"wiki-guide/GitHub-Repo-Guide/","title":"Repo Guide","text":""},{"location":"wiki-guide/GitHub-Repo-Guide/#github-repo-guide","title":"GitHub Repo Guide","text":"<p>Just joining or starting a new project and need a repository to store your work? You've come to the right place! Below we have compiled guidance on conventions and best practices for maintaining a shared (or shareable) repository of your work.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#setting-up-a-new-organization-repository","title":"Setting up a New Organization Repository","text":"<p>Note</p> <p>We recommend doing development in a public repo, or at least publishing the repo in which development was done at the time of publication/release. However, if you're looking to have a public-facing repo and a private repo for development, please be sure to read our guidance on the Two Repo Problem before proceeding.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#standard-files","title":"Standard Files","text":"<p>For each repository, include the following files in the root directory as soon as possible; they can (and should) be instantiated when you create a new repository.</p> <ul> <li>README.md</li> <li>LICENSE.md</li> <li>.gitignore</li> <li>software requirements</li> <li>CITATION.cff</li> </ul> <p>More recommendations are discussed below.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#readme","title":"README","text":"<p>The README.md file is what everyone will notice first when they open your repository on GitHub. When creating your repo be sure to include a brief description, as this will populate the <code>About</code> field in the top right of your repo, as well as start your README with some text.</p> <p>Once you've created your repo, populate your README (you can do this by clicking on the file \"README.md\", then clicking the pencil at the top left to edit). Editing your README in the browser allows you to preview the formatting of the file before committing changes. The content of your README may vary based on the purpose or goal of your repo, but there are key elements that should always be included.</p> <ul> <li>Summary of the repo:<ul> <li>This could be a simple explanation of what the package or tool developed in your repo is intended to do,</li> <li>Or an abstract describing your research.</li> </ul> </li> <li>Detailed documentation on how to access and use the project software (User Guide).  <ul> <li>Including installation of dependencies.</li> <li>If your tool requires input be in a particular format, this would be included in the README. It would also help to include an example file demonstrating the format.</li> </ul> </li> <li>Information about the sources you've used (links and what they were used for), such as:<ul> <li>Tools from other repos</li> <li>Data for analysis</li> </ul> </li> </ul> <p>For more inspiration on making an awesome README, check out this list.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#license","title":"LICENSE","text":""},{"location":"wiki-guide/GitHub-Repo-Guide/#1-select-a-license","title":"1. Select a license","text":"<p>Alongside the appropriate stakeholders, select a license that is Open Source Initiative (OSI) compliant.</p> <p>Remember</p> <p>A public repository on GitHub with no license can be viewed and forked by others under GitHub's ToS, but unless the author associates a license, it is unclear what others are allowed to do with it legally. Adding an OSI license can help others feel comfortable contributing!</p> <p>For more information on how to choose a license and why it matters, see Choose A License and A Quick Guide to Software Licensing for the Scientist-Programmer by A. Morin, et al.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#2-add-licensemd-to-the-repository","title":"2. Add LICENSE.md to the repository","text":"<p>Once a license has been chosen, add a LICENSE.md file to the root of the repository. An easy way to do this is using a GitHub-provided license template. Do not forget to update necessary fields in the template.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#gitignore","title":"GITIGNORE","text":"<p>The <code>.gitignore</code> file is an important tool for maintaining a clean repository by ensuring that git will not track temp files of any and all your collaborators (no pesky <code>pycache</code> or <code>.DS_Store</code> files floating around).</p> <p>GitHub has premade <code>.gitignore</code> files which can be selected from a dropdown when creating a repo. They are available for review at github/gitignore and are generally tailored to particular languages (eg., R or Python), operating systems, etc. The initial choice can be updated as needed. In particular, we recommend selecting a template based on the primary language used for your work.</p> <p>If you or anyone on your team uses a Mac (or if you intend to encourage outside collaboration on this repo), add</p> <pre><code># Mac system\n.DS_Store\n</code></pre> <p>at the end of the <code>.gitignore</code> file.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#software-requirements-file","title":"Software Requirements File","text":"<p>It is also advisable to include a machine-readable file with minimal software requirements for your project. For Python projects, this often takes the form of a <code>requirements.txt</code> file containing the packages and their versions that were used (eg., <code>pandas==2.0.1</code>). If you use <code>conda</code>, you may instead opt for an <code>environment.yml</code>. These are essential to ensuring the reproducibility and interoperability of your work (by yourself and others). Note that they should not be listed in the README.</p> <p>For more information on managing these environments and generating such files programmatically, see the wiki entry Virtual Environments.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#citation","title":"CITATION","text":"<p>Make it easier for people to cite your project by including a CITATION.cff file; you can copy-paste the template below.</p> <p>As with journal publications, we expect to be cited when someone uses our code. To facilitate proper attribution, GitHub will automatically read a CITATION.cff file and display a link to \"cite this repository\". This file is also used to populate metadata fields in a Zenodo record when auto-generating a DOI. As with any other component of your project, this file may change over the project's lifespan (see Digital Product Life Cycle for details), but it should be present and updated before any release.</p> <p>Providing this file is as simple as copying the below example and filling in your information before uploading it to your repo. More examples and information about the Citation File Format can be found on the citation-file-format repo, including helpful related tools.</p> <p>You can check your CITATION.cff file prior to upload using this validator tool.</p> <p>Note</p> <ul> <li>When adding a DOI to your citation (<code>doi</code>), be sure to use the version-agnostic DOI from Zenodo. Since the DOI is not generated until after the release, this ensures there will never be an \"incorrect\" DOI associated to the release\u2014correct version reference is ensured through the <code>version</code> key, which should always be updated before generating a new release.</li> <li>Subcategories of <code>preferred-citation</code> do not get bullet points, but the first subcategory of <code>references</code> must be bulleted (as below).</li> <li>This is generally intended as a reference for your code. Preferred citation can be used for the paper, though it is better to ask in the <code>README</code> that someone cites both and provide the paper reference there (only the <code>preferred-citation</code> will show up to be copied from the citation box if it is included).</li> </ul> <pre><code>abstract: \"&lt;describe your code/package&gt;\"\nauthors:\n- family-names:\n  given-names: \"&lt;First M.I.&gt;\"\n  orcid: \"https://orcid.org/&lt;ORCID #&gt;\"\ncff-version: 1.2.0\ndate-released: \"YYYY-MM-DD\"\nidentifiers:\n  - description: \"The GitHub release URL of tag &lt;version&gt;.\"\n    type: url\n    value: \"https://github.com/Imageomics/&lt;repo&gt;/releases/tag/&lt;tag-name&gt;\"\n  - description: \"The GitHub URL of the commit tagged with &lt;tag-name&gt;.\"\n    type: url\n    value: \"https://github.com/Imageomics/&lt;repo&gt;/tree/&lt;commit-hash&gt;\"\nkeywords:\n  - imageomics\nlicense:\nmessage: \"If you find this software helpful in your research, please cite both the software and our paper.\"\nrepository-code: \"https://github.com/Imageomics/&lt;repo&gt;\"\ntitle: \"&lt;repo title&gt;\"\nversion: &lt;release version&gt;\ndoi: &lt;DOI from Zenodo&gt;    # version agnostic DOI\ntype: software\npreferred-citation:\n  type: article\n  authors:\n    - family-names:\n      given-names:\n    - family-names:\n      given-names:\n  title: \n  year:\n  journal:\n  doi: \nreferences:\n  - authors:\n      - family-names:\n        given-names:\n      - family-names:\n        given-names:\n    title: \n    version:\n    type:\n    doi: \n    date-released:\n</code></pre>"},{"location":"wiki-guide/GitHub-Repo-Guide/#recommended-files","title":"Recommended Files","text":"<p>Though the following files are not included in every repository and do not have a simple selection process integrated into GitHub, they are extremely important (if not essential) to maintaining FAIR principles and reproducibility in projects, as well as ensuring proper attribution for your work.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#contributing","title":"CONTRIBUTING","text":"<p>If you are looking to open your project to more public contributions, it is a good idea to include contributing guidelines. This could take the form of a \"CONTRIBUTING.md\" file or a subsection of your README.</p> <p>Contributing guidelines are important to maintain consistency across the way people work on a project. It is important to establish conventions about the important things while avoiding excessive constraints and bureaucracy that would make contributing a pain. Important things include efficient and effective communication.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#zenodo-metadata","title":"Zenodo Metadata","text":"<p>When using the Zenodo-GitHub integration for automatic DOI generation, tracking metadata beyond the basics (authors, keywords, title, etc.) requires manual updates to the Zenodo record. The solution for this is to include a <code>.zenodo.json</code> file to keep track of this information (e.g., grant funding and references).</p> <p>A <code>.zenodo.json</code> can be created by applying cffconvert to your <code>CITATION.cff</code> (without the references, as these are not supported). Then add the references and other metadata back in to the JSON (following the Zenodo dev guide). Alterntatively, The example below can simply be copied into a new file and updated with the appropriate information (comments should be removed prior to upload).</p> <p>Note</p> <p>The <code>publication_date</code> and <code>version</code> will need to be updated along with the <code>CITATION.cff</code> for each release.</p> <pre><code>{\n    \"creators\": [\n      {\n          \"name\": \"family-names, given-names\",\n          \"orcid\": \"\",\n          \"affiliation\": \"\"\n      },\n      {\n          \"name\": \"family-names, given-names\",\n          \"orcid\": \"\",\n          \"affiliation\": \"\"\n      }\n    ],\n    \"description\": \"\", // Ex: abstract from the citation, HTML can be used for formatting\n    \"keywords\": [  // Add the same list of keywords as in your CITATION.cff\n      \"imageomics\"\n    ],\n    \"title\": \"&lt;repo title&gt;\",\n    \"version\": \"&lt;release version&gt;\",\n    \"license\": \"&lt;license&gt;\",           // Check docs for codes: https://developers.zenodo.org/#representation\n    \"publication_date\": \"YYYY-MM-DD\",\n    \"grants\": [\n        {\n            \"id\": \"021nxhr62::2118240\"  // Imageomics (&lt;NSF code&gt;::&lt;Imageomics Grant #&gt;)\n        }\n    ] \n}\n</code></pre> <p>Example <code>.zenodo.json</code></p> <p>The Zenodo JSON for BioCLIP 2 provides an example that includes a grant, references, and an associated paper (<code>related_identifiers</code>), which is also listed under <code>notes</code> for additional citation. We also recommend including this format validation workflow, which will run if either the <code>.zenodo.json</code> or the workflow itself is edited.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#additional-considerations","title":"Additional Considerations","text":""},{"location":"wiki-guide/GitHub-Repo-Guide/#formatting-and-naming-conventions","title":"Formatting and Naming Conventions","text":""},{"location":"wiki-guide/GitHub-Repo-Guide/#dates-and-times","title":"Dates and Times","text":"<p>For interoperability and to avoid ambiguity, dates and times should be reported in ISO 8601 format.</p> <ul> <li>For dates, this means <code>YYYY-MM-DD</code> (for ISO 8601 compliance, the dashes are required).</li> <li>For times, use <code>THHMMSS</code> in 24-hour format.</li> <li>For example, the moment when there were 60 seconds left before New Year 2000 would be <code>1999-12-31T235900</code>.</li> </ul>"},{"location":"wiki-guide/GitHub-Repo-Guide/#branches","title":"Branches","text":"<ul> <li>Primary branch: <code>main</code></li> <li>Other branches follow the pattern <code>category/reference/description</code>:<ul> <li>category: <code>feature</code>, <code>bugfix</code>, <code>experiment</code><ul> <li><code>feature</code> is for new functionality</li> <li><code>bugfix</code> is for fixing errors</li> <li><code>experiment</code> is for more open-ended work</li> </ul> </li> <li>the associated issue (if no issue, put <code>no-ref</code>), formatted as <code>issue-NN</code></li> <li>description: brief description, e.g., <code>solve-world-hunger</code></li> </ul> </li> <li>Example: <code>git branch feature/issue-1/general-ai</code></li> </ul>"},{"location":"wiki-guide/GitHub-Repo-Guide/#commits","title":"Commits","text":"<p>To combine human- and computer-readability into commit messages, follow the Conventional Commits specification.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#workflow","title":"Workflow","text":"<p>Do not conduct routine work in the <code>main</code> branch. Only do one thing on a branch at a time. Prune a branch once its purpose is fulfilled and it is merged (i.e., delete it).</p> <p>For more information on creating, merging, and deleting branches, see the GitHub Workflow Guide.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#general-repository-structure","title":"General Repository Structure","text":"<p>In addition to the standard files recommended for every repo, you will likely have some code, notebooks, and data. For an easily accessible and readable repo, it is good to organize these files within a clear directory (folder) structure, such as</p> <pre><code>Project_Directory\n    - scripts\n    - notebooks\n    - src\n    - data\n</code></pre> <p>Note</p> <p>Depending on the size of your data, <code>data</code> may only be local on your machine in which case it is good to include instructions to access the data where appropriate.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#working-on-github","title":"Working on GitHub","text":"<p>After the initial creation of a repo on the GitHub website, there are two primary modes of interacting with it.</p> <ol> <li> <p>Through git on the Command Line</p> <p>This requires a <code>bash</code> or <code>zsh</code> shell on your computer. On Mac you can use terminal, while Windows requires installing git and a bash emulator.</p> </li> <li> <p>Through the GitHub Desktop App, GitHub Desktop</p> <p>GitHub provides documentation to get started on Mac or Windows, as well as extensive documentation on use cases we discuss throughout the wiki GitHub's Guide to contributing and collaborating using GitHub desktop.</p> </li> </ol> <p>Note</p> <p>The bulk of our step-by-step guides will outline interaction through the command line, but the same principles apply to using GitHub Desktop.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#cloning-a-repository","title":"Cloning a Repository","text":"<p>Navigate to the main (\"&lt;&gt; Code\") page of your repository and click the green button at the top right corner (as shown below) and copy the link (for command line) or select \"Open with GitHub Desktop\". For command line interaction, navigate within the <code>bash</code> shell to the directory where you would like to place your local copy of the repo (<code>cd &lt;folder_name&gt;</code>), then clone the repo into that folder (<code>git clone &lt;repo_url&gt;</code>), this will generate a local copy of the repo on your computer.</p> <p></p> <p>If you would like a specific branch, use <code>git clone -b &lt;branch_name&gt; &lt;repo_url&gt;</code>.</p>"},{"location":"wiki-guide/GitHub-Repo-Guide/#workflow-summary","title":"Workflow Summary","text":"<p>Generally, repositories are organized around an Imageomics Project/Topic/Team, eg., butterflies. These broader topics may contain various projects organized under a GitHub Team focused on that topic. Both projects and repositories may be linked to teams, providing an organizational structure upon which to plan and manage tasks while maintaining a clear link/connection to the work being done on those tasks. Note that a project may encapsulate multiple repositories just as a repository may be referenced by multiple projects.</p> <p>Ideally, each task will be linked to an issue in the relevant repository. Team members may then be assigned tasks, and asynchronous discussions about the task can be recorded on its issue page in the repository. To accomplish the task, a new branch should be created following the branch naming conventions; do not work directly on the <code>main</code> branch. Once the task is completed, a pull request can be opened to merge the changes into the main branch (see the GitHub Workflow Guide and the PR Guide for more details on this process). Reviewers may be assigned to each pull request to ensure compatibility and that the proposed solution functions as expected/needed; this is an opportunity for more dialogue.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/","title":"Glossary for Imageomics","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#imageomics-glossary","title":"Imageomics Glossary","text":"<p>This glossary is designed as a resource for members of the Imageomics Institute from various backgrounds to familiarize themselves with key terms and concepts encountered in our work.</p> <p>It includes concepts in biology, ecology, genetics, machine learning and artificial intelligence, computer science, and software engineering.</p> <p>Definitions are not meant to be comprehensive. Ideally, they will be tailored to our institute's context.</p> <p>It is meant to be a collaborative effort, so please contribute terms you would like defined, definitions you know, or corrections for errors you notice!</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#a","title":"A","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#application-programming-interface-api","title":"Application Programming Interface (API)","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#autoencoder","title":"Autoencoder","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#b","title":"B","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#c","title":"C","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#care-principles-for-indigenous-data-governance","title":"CARE Principles for Indigenous Data Governance","text":"<p>\"People and purpose-oriented\" to complement FAIR Principles.</p> <p>Collective Benefit</p> <p>Authority to Control</p> <p>Responsibility</p> <p>Ethics</p> <p>For more information, see CARE Principles for Indigenous Data Governance.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#contrastive-language-image-pre-training-clip","title":"Contrastive Language-Image Pre-training (CLIP)","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#d","title":"D","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#decoder","title":"Decoder","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#dimensionality-reduction","title":"Dimensionality Reduction","text":"<p>Used in machine learning and data analysis to refer to a set of methods used to reduce the number of variables or features under consideration to a smaller subset with the greatest explanatory power without drastically reducing the accuracy of the model or analysis. The purpose is to exclude irrelevant, redundant, and noisy information, thereby improving computational complexity and model interpretability.</p> <p>That is, it seeks to preserve the \"most important\" variables or features of the data based on some quantitative metric, such as variance, while removing \"less important\" variables or features. This is especially helpful when using high-dimensional data such as images or genomes.</p> <p>Dimensionality reduction techniques can be subdivided into two main categories:</p> <ul> <li>Feature Extraction</li> <li>Feature Selection</li> </ul>"},{"location":"wiki-guide/Glossary-for-Imageomics/#docker","title":"Docker","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#e","title":"E","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#ecology","title":"Ecology","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#epoch-in-machine-learning","title":"Epoch (in machine learning)","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#encoder","title":"Encoder","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#experiment-in-machine-learning","title":"Experiment (in machine learning)","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#f","title":"F","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#fair-data-principles","title":"FAIR Data Principles","text":"<p>Findable -- metadata and data easily found by both humans and machines</p> <p>Accessible -- clear indication of how to access data once it is found.</p> <p>Interoperable -- ability to integrate with other data and be used by various systems (applications and workflows).</p> <p>Reusable -- clearly described so it is easily used by others.</p> <p>For more information, see FAIR principles.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#feature","title":"Feature","text":"<p>In machine learning and data science, a feature is a single measurable property or characteristic of the phenomenon under observation. With tabular data, a feature is a column in the dataset used by a model to make predictions. In genomics, a feature could be, for example, gene expression levels, the presence (or absence) of certain genetic variants (such as SNPs, insertions and deletions (indels), and others), or epigenetic markers.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#feature-extraction","title":"Feature Extraction","text":"<p>A set of dimensionality reduction techniques used to map raw data to a smaller set of features. Example techniques include PCA, MDS, t-SNE, autoencoders, and Fourier or wavelet transforms.</p> <p>The key difference from feature selection is that feature extraction generates a new set of features from the original dataset by projecting or mapping the data into a new feature space rather than selecting from existing features.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#feature-selection","title":"Feature Selection","text":"<p>A method to select a subset of relevant features for use in model construction.</p> <p>The key difference from feature extraction is that feature selection does not generate new features but rather identifies the most meaningful existing features in a dataset by excluding redundant or irrelevant features. For example, in genomics, feature selection would involve selecting the most important gene(s) relevant to a certain phenotype among thousands of genes.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#feature-space","title":"Feature Space","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#g","title":"G","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#genome-wide-association-study-gwas","title":"Genome-Wide Association Study (GWAS)","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#h","title":"H","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":"<p>The process of selecting the best hyperparameters for a machine learning model by minimizing the loss function. This can be done through experiments or in some cases, using optimization techniques. Hyperparameters are parameters that are set by the researcher before training and are not learned during the training process. Some examples of common hyperparameters are learning rate, number of epochs, number of clusters (k) in k-means clustering, and many others.  </p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#i","title":"I","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#imageomics","title":"Imageomics","text":"<p>i-'mi-j\u0259-'\u014d-miks</p> <p>A new scientific field in which computational (machine learning) tools built around biological knowledge bases are used by biologists to analyze image data in order to characterize patterns and gain insights into traits and relationships at individual, population and species scales\u2014insights that then get incorporated into the algorithms that run the tools.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#j","title":"J","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#k","title":"K","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#k-means-clustering","title":"K-Means Clustering","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#l","title":"L","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#latent-space","title":"Latent Space","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#learning-rate","title":"Learning Rate","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#loss-function","title":"Loss Function","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#m","title":"M","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#multidimensional-scaling-mds","title":"Multidimensional Scaling (MDS)","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#n","title":"N","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#nucleotide","title":"Nucleotide","text":"<p>The fundamental building blocks of DNA and RNA. A nucleotide is composed of a base and a sugar-phosphate backbone.</p> <p>Bases for DNA: adenine (A), guanine (G), cytosine (C), and thymine (T).</p> <p>Bases for RNA: adenine (A), guanine (G), cytosine (C), and uracil (U).</p> <p>Backbone sugar for RNA: ribose</p> <p>Backbone sugar for DNA: deoxyribose (one less oxygen atom than ribose)</p> <p>The bases A, G, and C are the same molecule for DNA and RNA. T and U are incorporated into their sequences differently due to the presence of substrate molecules accessible to DNA polymerase and RNA polymerase, which are the enzymes responsible for \"manufacturing\" the relevant sequences. DNA polymerase must use deoxyribonucleotides (dNTPs), and RNA polymerase must use ribonucleotide triphosphates (NTPs). Again, the difference is that there is one less oxygen atom in dNTPs vs NTPs. Cells have dATPs, dGTPs, dCTPs, and dTTPs for DNA polymerase to incorporate into a DNA sequence, but there are normally no dUTPs (and in cases where dUTPs are present and incorporated into DNA, \"error correction\" enzymes replace them using dTTPs). Likewise for RNA polymerase, ATP, GTP, CTP and UTP are available, but TTP is not. These substrates also serve other important purposes, such as how ATP (adenosine triphosphate) is used as a primary source of energy for many cellular processes.</p> <p>A DNA or RNA molecule consists of a chain of the four relevant nucleotides in a sequence, where the order of A, G, C, and T in the DNA sequence determines the \"blueprint\" for the organism, and the order and length of A, G, C, and U in an RNA sequence determines the purpose and function of the RNA molecule, which can be a messenger RNA (mRNA) that encodes a protein, a microRNA (miRNA) which are short RNAs that help regulate gene expression by binding to other mRNAs, and many others.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#o","title":"O","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#ontology","title":"Ontology","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#p","title":"P","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#phenotype","title":"Phenotype","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#phylogeny","title":"Phylogeny","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#pre-training","title":"Pre-training","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#principal-component-analysis-pca","title":"Principal Component Analysis (PCA)","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#q","title":"Q","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#r","title":"R","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#s","title":"S","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#single-nucleotide-polymorphism-snp","title":"Single Nucleotide Polymorphism (SNP)","text":"<p>A SNP (pronounced \"snip\") is a variation in the nucleotide present at a single position in a DNA sequence among individuals in a species. For example, a SNP may be the replacement of a cytosine (C) by a thymine (T) at the same location in a stretch of DNA, where C is observed in a subset of individuals and T is observed in the others.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#snakemake","title":"Snakemake","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#subspecies","title":"Subspecies","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#supervised-learning","title":"Supervised Learning","text":"<p>As opposed to unsupervised learning, supervised learning methods learn from labeled data. That is, it is trained using input data that is labeled with corresponding outputs, such as the input of an image and the output of a classification.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#t","title":"T","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#taxonomy","title":"Taxonomy","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#t-distributed-stochastic-neighbor-embedding-t-sne","title":"t-Distributed Stochastic Neighbor Embedding (t-SNE)","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#trait","title":"Trait","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#transfer-learning","title":"Transfer Learning","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#u","title":"U","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>As opposed to supervised learning, unsupervised learning detects patterns or structures within the input data without any labels. Clustering and dimensionality reduction techniques are some examples.</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#v","title":"V","text":"<p>VLMs (Vision-Language Models)</p>"},{"location":"wiki-guide/Glossary-for-Imageomics/#w","title":"W","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#x","title":"X","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#y","title":"Y","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#z","title":"Z","text":""},{"location":"wiki-guide/Glossary-for-Imageomics/#zero-shot-prediction","title":"Zero-Shot Prediction","text":""},{"location":"wiki-guide/Guide-to-GitHub-Projects/","title":"Projects Guide","text":""},{"location":"wiki-guide/Guide-to-GitHub-Projects/#guide-to-github-projects","title":"Guide to GitHub Projects","text":"<p>When starting a new project, it can be helpful to have a shared tracker or project board to keep track of who is responsible for which tasks, what has and has not yet been done, which tasks are necessary for various goals of the project, and so on. Note that many of these items are also helpful when working on a project by oneself. GitHub provides a very useful tool for just this purpose: GitHub Projects. GitHub projects can be linked with one or more GitHub repos to automatically keep track of issues and PRs associated with your project.</p>"},{"location":"wiki-guide/Guide-to-GitHub-Projects/#some-advantages-of-working-with-github-projects","title":"Some advantages of working with GitHub Projects","text":"<ul> <li>Different view options that sync automatically.</li> <li>Easy to see who's doing what and keep track of progress.<ul> <li>Profile images show up for assignees to various tasks.</li> <li>Clicking on an assignees profile image will show only that person's assigned tasks (similarly for labels and milestones attached to tasks).</li> </ul> </li> <li>More columns/categories can be added for different aspects of the project.</li> <li>Multiple repos can be linked to a single project.<ul> <li>Access to issues is controlled by repo access permissions; only the existence of issues is universal to the project.</li> </ul> </li> <li>Closing an issue will automatically move the task to \"Done\".</li> <li>Tasks can be reordered within their columns/categories to keep most pressing tasks at the top.</li> </ul>"},{"location":"wiki-guide/Guide-to-GitHub-Projects/#interacting-with-github-projects","title":"Interacting with GitHub Projects","text":"<p>To help you get started working with GitHub Projects, we have a General Project Template with both a Taskboard and Table view initialized, along with label and milestone displays turned on. Both of these views will automatically stay updated so that each member of the project can utilize whichever version they find most informative.</p> <p>Issues can be added directly to the project board/table or on the repo. If added through the repo, they must be linked to the project and have status assigned. Milestones must be created on the repo (under the Issues tab, select \"Milestones\" to create one), similarly for labels.</p> <p>Note</p> <p>Issues on a project board that are linked to a repository to which a user does not have access will not be visible to them, even if they have access to the project. They will show up (for that user) as unidentified issues with no status.</p>"},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/","title":"HF DatasetCard Template Imageomics","text":"","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#dataset-card-for-dataset-pretty_name","title":"Dataset Card for [dataset pretty_name]","text":"","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#dataset-details","title":"Dataset Details","text":"","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#dataset-description","title":"Dataset Description","text":"<ul> <li>Curated by: list curators (authors for data citation, moved up)</li> <li>Language(s) (NLP): [More Information Needed]</li> </ul> <ul> <li>Homepage: </li> <li>Repository: [related project repo]</li> <li>Paper: </li> </ul> <p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#supported-tasks-and-leaderboards","title":"Supported Tasks and Leaderboards","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#dataset-structure","title":"Dataset Structure","text":"","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#data-instances","title":"Data Instances","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#data-fields","title":"Data Fields","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#data-splits","title":"Data Splits","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#dataset-creation","title":"Dataset Creation","text":"","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#curation-rationale","title":"Curation Rationale","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#source-data","title":"Source Data","text":"","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#data-collection-and-processing","title":"Data Collection and Processing","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#who-are-the-source-data-producers","title":"Who are the source data producers?","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#annotations","title":"Annotations","text":"","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#annotation-process","title":"Annotation process","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#who-are-the-annotators","title":"Who are the annotators?","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#personal-and-sensitive-information","title":"Personal and Sensitive Information","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#considerations-for-using-the-data","title":"Considerations for Using the Data","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#bias-risks-and-limitations","title":"Bias, Risks, and Limitations","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#recommendations","title":"Recommendations","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#licensing-information","title":"Licensing Information","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#citation","title":"Citation","text":"<p>[More Information Needed]</p> <p>BibTeX:</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#acknowledgements","title":"Acknowledgements","text":"<p>This work was supported by the Imageomics Institute, which is funded by the US National Science Foundation's Harnessing the Data Revolution (HDR) program under Award #2118240 (Imageomics: A New Frontier of Biological Information Powered by Knowledge-Guided Machine Learning). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#glossary","title":"Glossary","text":"","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#more-information","title":"More Information","text":"","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#dataset-card-authors","title":"Dataset Card Authors","text":"<p>[More Information Needed]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_Imageomics/#dataset-card-contact","title":"Dataset Card Contact","text":"<p>[More Information Needed--optional]</p>","tags":["biology","image","animals","CV"]},{"location":"wiki-guide/HF_DatasetCard_Template_mkdocs/","title":"Dataset Card Template","text":""},{"location":"wiki-guide/HF_DatasetCard_Template_mkdocs/#dataset-card-template","title":"Dataset Card Template","text":"<p>Below is the Dataset Card template for Imageomics. You can download or copy the dataset card content and paste it into a new Markdown file to create a README for your dataset.</p> Imageomics Download template from GitHub <pre><code>---\nlicense: cc0-1.0\nlanguage:\n- en\npretty_name:\ntask_categories: # ex: image-classification, see key list at https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/pipelines.ts\ntags:\n- biology\n- image\n- animals\n- CV\nsize_categories: # ex: n&lt;1K, 1K&lt;n&lt;10K, 10K&lt;n&lt;100K, 100K&lt;n&lt;1M, ...\ndescription: # Add a short description (summary) of your dataset, this will render as part of the CardData object through the API, which can thus be used in applications such as the Imageomics Catalog\n---\n\n&lt;!--\n\nNOTE: Add more tags (your particular animal, type of model and use-case, etc.).\n\nAs with your GitHub Project repo, it is important to choose an appropriate license for your dataset. The default license is [CC0](https://creativecommons.org/publicdomain/zero/1.0/) (public domain dedication, see [Dryad's explanation of why to use CC0](https://blog.datadryad.org/2023/05/30/good-data-practices-removing-barriers-to-data-reuse-with-cc0-licensing/)). Alongside the appropriate stakeholders (eg., your PI, co-authors), select a license that is [Open Source Initiative](https://opensource.org/licenses) (OSI) compliant.\nFor more information on how to choose a license and why it matters, see [Choose A License](https://choosealicense.com) and [A Quick Guide to Software Licensing for the Scientist-Programmer](https://doi.org/10.1371/journal.pcbi.1002598) by A. Morin, et al.\nSee the [Imageomics policy for licensing](https://imageomics.github.io/Imageomics-guide/wiki-guide/Digital-products-release-licensing-policy/) for more information.\n\nSee more options for the above information by clicking \"edit dataset card\" on your repo.\n\nFill in as much information as you can at each location that says \"More information needed\".\n--&gt;\n\n&lt;!--\nImage with caption (jpg or png):\n|![Figure #](https://huggingface.co/datasets/imageomics/&lt;data-repo&gt;/resolve/main/&lt;filepath&gt;)|\n|:--|\n|**Figure #.** [Image of &lt;&gt;](https://huggingface.co/datasets/imageomics/&lt;data-repo&gt;/raw/main/&lt;filepath&gt;) &lt;caption description&gt;.|\n--&gt;\n\n&lt;!--\nNotes on styling:\n\nTo render LaTex in your README, wrap the code in `\\\\(` and `\\\\)`. Example: \\\\(\\frac{1}{2}\\\\)\n\nEscape underscores (\"_\") with a \"\\\". Example: image\\_RGB\n--&gt;\n\n# Dataset Card for [dataset pretty_name]\n\n&lt;!-- Provide a quick summary of what the dataset is or can be used for. --&gt; \n\n## Dataset Details\n\n### Dataset Description\n\n- **Curated by:** list curators (authors for _data_ citation, moved up)\n- **Language(s) (NLP):** [More Information Needed]\n&lt;!-- Provide the basic links for the dataset. These will show up on the sidebar to the right of your dataset card (\"Curated by\" too). --&gt;\n- **Homepage:** \n- **Repository:** [related project repo]\n- **Paper:** \n\n\n&lt;!-- Provide a longer summary of what this dataset is. --&gt;\n[More Information Needed]\n\n&lt;!--This dataset card aims to be a base template for new datasets. It has been generated using [this raw template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/datasetcard_template.md?plain=1), and further altered to suit Imageomics Institute needs.--&gt;\n\n\n### Supported Tasks and Leaderboards\n[More Information Needed]\n\n&lt;!-- Provide benchmarking results --&gt;\n\n\n## Dataset Structure\n\n&lt;!-- This section provides a description of the dataset fields, and additional information about the dataset structure such as criteria used to create the splits, relationships between data points, etc. --&gt;\n\n&lt;!-- Provide format of the dataset, ex:\n\n```\u200b\n/dataset/\n    &lt;species_1&gt;/\n        &lt;img_id 1&gt;.png\n        &lt;img_id 2&gt;.png\n        ...\n        &lt;img_id n&gt;.png\n    &lt;species_2&gt;/\n        &lt;img_id 1&gt;.png\n        &lt;img_id 2&gt;.png\n        ...\n        &lt;img_id n&gt;.png\n    ...\n    &lt;species_N&gt;/\n        &lt;img_id 1&gt;.png\n        &lt;img_id 2&gt;.png\n        ...\n        &lt;img_id n&gt;.png\n    metadata.csv\n```\u200b\n\n--&gt;\n\n### Data Instances\n[More Information Needed]\n\n&lt;!--\nDescribe data files\n\nEx: All images are named &lt;img_id&gt;.png, each within a folder named for the species. They are 1024 x 1024, and the color has been standardized using &lt;link to color standardization package&gt;.\n--&gt;\n\n### Data Fields\n[More Information Needed]\n&lt;!--\nDescribe the types of the data files or the columns in a CSV with metadata.\n\nEx: \n**metadata.csv**:\n  - `img_id`: Unique identifier for the dataset. \n  - `specimen_id`: ID of specimen in the image, provided by museum data source. There are multiple images of a single specimen.\n  - `species`: Species of the specimen in the image. There are N different species of &lt;genus&gt; of &lt;animal&gt;.\n  - `view`: View of the specimen in the image (e.g., `ventral` or `dorsal` OR `top` or `bottom`, etc.; specify options where reasonable).\n  - `file_name`: Relative path to image from the root of the directory (`&lt;species&gt;/&lt;img_id&gt;.png`); allows for image to be displayed in the dataset viewer alongside its associated metadata.\n--&gt;\n\n### Data Splits\n[More Information Needed]\n&lt;!--\nGive your train-test splits for benchmarking; could be as simple as \"split is indicated by the `split` column in the metadata file: `train`, `val`, or `test`.\" Or perhaps this is just the training dataset and other datasets were used for testing (you may indicate which were used).\n--&gt;\n\n## Dataset Creation\n\n### Curation Rationale\n[More Information Needed]\n&lt;!-- Motivation for the creation of this dataset. For instance, what you intended to study and why that required curation of a new dataset (or if it's newly collected data and why the data was collected (intended use)), etc. --&gt;\n\n### Source Data\n\n&lt;!-- This section describes the source data (e.g., news text and headlines, social media posts, translated sentences, ...). As well as an original source it was created from (e.g., sampling from Zenodo records, compiling images from different aggregators, etc.) --&gt;\n\n#### Data Collection and Processing\n[More Information Needed]\n&lt;!-- This section describes the data collection and processing process such as data selection criteria, filtering and normalization methods, re-sizing of images, tools and libraries used, etc. \nThis is what _you_ did to it following collection from the original source; it will be overall processing if you collected the data initially.\n--&gt;\n\n#### Who are the source data producers?\n[More Information Needed]\n&lt;!-- This section describes the people or systems who originally created the data.\n\nEx: This dataset is a collection of images taken of the butterfly collection housed at the Ohio State University Museum of Biological Diversity. The associated labels and metadata are the information provided with the collection from biologists that study butterflies and supplied the specimens to the museum.\n --&gt;\n\n\n### Annotations\n&lt;!-- \nIf the dataset contains annotations which are not part of the initial data collection, use this section to describe them. \n\nEx: We standardized the taxonomic labels provided by the various data sources to conform to a uniform 7-rank Linnean structure. (Then, under annotation process, describe how this was done: Our sources used different names for the same kingdom (both _Animalia_ and _Metazoa_), so we chose one for all (_Animalia_). --&gt;\n\n#### Annotation process\n[More Information Needed]\n&lt;!-- This section describes the annotation process such as annotation tools used, the amount of data annotated, annotation guidelines provided to the annotators, interannotator statistics, annotation validation, etc. --&gt;\n\n#### Who are the annotators?\n[More Information Needed]\n&lt;!-- This section describes the people or systems who created the annotations. --&gt;\n\n### Personal and Sensitive Information\n[More Information Needed]\n&lt;!-- \nFor instance, if your data includes people or endangered species. --&gt;\n\n\n## Considerations for Using the Data\n[More Information Needed]\n&lt;!--\nThings to consider while working with the dataset. For instance, maybe there are hybrids and they are labeled in the `hybrid_stat` column, so to get a subset without hybrids, subset to all instances in the metadata file such that `hybrid_stat` is _not_ \"hybrid\".\n--&gt;\n\n### Bias, Risks, and Limitations\n[More Information Needed]\n&lt;!-- This section is meant to convey both technical and sociotechnical limitations. Could also address misuse, malicious use, and uses that the dataset will not work well for.--&gt;\n\n&lt;!-- For instance, if your data exhibits a long-tailed distribution (and why). --&gt;\n\n### Recommendations\n[More Information Needed]\n&lt;!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. --&gt;\n\n## Licensing Information\n[More Information Needed]\n\n&lt;!-- See notes at top of file about selecting a license. \nIf you choose CC0: This dataset is dedicated to the public domain for the benefit of scientific pursuits. We ask that you cite the dataset and journal paper using the below citations if you make use of it in your research.\n\nBe sure to note different licensing of images if they have a different license from the compilation.\nex: \nThe data (images and text) contain a variety of licensing restrictions mostly within the CC family. Each image and text in this dataset is provided under the least restrictive terms allowed by its licensing requirements as provided to us (i.e, we impose no additional restrictions past those specified by licenses in the license file).\n\nEOL images contain a variety of licenses ranging from [CC0](https://creativecommons.org/publicdomain/zero/1.0/) to [CC BY-NC-SA](https://creativecommons.org/licenses/by-nc-sa/4.0/).\nFor license and citation information by image, see our [license file](https://huggingface.co/datasets/imageomics/treeoflife-10m/blob/main/metadata/licenses.csv).\n\nThis dataset (the compilation) has been marked as dedicated to the public domain by applying the [CC0 Public Domain Waiver](https://creativecommons.org/publicdomain/zero/1.0/). However, images may be licensed under different terms (as noted above).\n--&gt;\n\n## Citation\n[More Information Needed]\n\n**BibTeX:**\n&lt;!--\nIf you want to include BibTex, replace \"&lt;&gt;\"s with your info \n\n**Data**\n```\u200b\n@misc{&lt;ref_code&gt;,\n  author = {&lt;author1 and author2&gt;},\n  title = {&lt;title&gt;},\n  year = {&lt;year&gt;},\n  url = {https://huggingface.co/datasets/imageomics/&lt;dataset_name&gt;},\n  doi = {&lt;doi once generated&gt;},\n  publisher = {Hugging Face}\n}\n```\u200b\n\n-for an associated paper:\n**Paper**\n```\u200b\n@article{&lt;ref_code&gt;,\n  title    = {&lt;title&gt;},\n  author   = {&lt;author1 and author2&gt;},\n  journal  = {&lt;journal_name&gt;},\n  year     =  &lt;year&gt;,\n  url      = {&lt;DOI_URL&gt;},\n  doi      = {&lt;DOI&gt;}\n}\n```\u200b\n--&gt;\n\n&lt;!---\nIf the data is modified from another source, add the following. \n\nPlease be sure to also cite the original data source(s):\n&lt;citation&gt;\n--&gt;\n\n\n## Acknowledgements\n\nThis work was supported by the [Imageomics Institute](https://imageomics.org), which is funded by the US National Science Foundation's Harnessing the Data Revolution (HDR) program under [Award #2118240](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2118240) (Imageomics: A New Frontier of Biological Information Powered by Knowledge-Guided Machine Learning). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.\n\n&lt;!-- You may also want to credit the source of your data, i.e., if you went to a museum or nature preserve to collect it. --&gt;\n\n## Glossary \n\n&lt;!-- [optional] If relevant, include terms and calculations in this section that can help readers understand the dataset or dataset card. --&gt;\n\n## More Information \n\n&lt;!-- [optional] Any other relevant information that doesn't fit elsewhere. --&gt;\n\n## Dataset Card Authors \n\n[More Information Needed]\n\n## Dataset Card Contact\n\n[More Information Needed--optional]\n&lt;!-- Could include who to contact with questions, but this is also what the \"Discussions\" tab is for. --&gt;\n</code></pre>"},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/","title":"HF ModelCard Template Imageomics","text":"","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#model-card-for-model-name","title":"Model Card for [Model Name]","text":"","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#model-details","title":"Model Details","text":"","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#model-description","title":"Model Description","text":"<ul> <li>Developed by: [More Information Needed]</li> <li>Model type: [More Information Needed]</li> <li>Language(s) (NLP): [More Information Needed]</li> <li>License: [More Information Needed -- choose a license (see above notes)]</li> <li>Fine-tuned from model: [More Information Needed]</li> </ul>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#model-sources","title":"Model Sources","text":"<ul> <li>Repository: [Project Repo]</li> <li>Paper: [More Information Needed--optional]</li> <li>Demo: [More Information Needed--encouraged]</li> </ul>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#uses","title":"Uses","text":"","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#direct-use","title":"Direct Use","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#downstream-use","title":"Downstream Use","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#out-of-scope-use","title":"Out-of-Scope Use","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#bias-risks-and-limitations","title":"Bias, Risks, and Limitations","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#recommendations","title":"Recommendations","text":"<p>Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#how-to-get-started-with-the-model","title":"How to Get Started with the Model","text":"<p>Use the code below to get started with the model.</p> <p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#training-details","title":"Training Details","text":"","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#training-data","title":"Training Data","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#training-procedure","title":"Training Procedure","text":"","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#preprocessing","title":"Preprocessing","text":"<p>[More Information Needed--encouraged]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#training-hyperparameters","title":"Training Hyperparameters","text":"<ul> <li>Training regime: [More Information Needed] </li> </ul>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#speeds-sizes-times","title":"Speeds, Sizes, Times","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#evaluation","title":"Evaluation","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#testing-data-factors-metrics","title":"Testing Data, Factors &amp; Metrics","text":"","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#testing-data","title":"Testing Data","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#factors","title":"Factors","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#metrics","title":"Metrics","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#results","title":"Results","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#summary","title":"Summary","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#model-examination","title":"Model Examination","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#environmental-impact","title":"Environmental Impact","text":"<p>Carbon emissions can be estimated using the Machine Learning Impact calculator presented in Lacoste et al. (2019).</p> <ul> <li>Hardware Type: [More Information Needed]</li> <li>Hours used: [More Information Needed]</li> <li>Cloud Provider: [More Information Needed]</li> <li>Compute Region: [More Information Needed]</li> <li>Carbon Emitted: [More Information Needed]</li> </ul>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#technical-specifications","title":"Technical Specifications","text":"<p>[More Information Needed--optional]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#model-architecture-and-objective","title":"Model Architecture and Objective","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#compute-infrastructure","title":"Compute Infrastructure","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#hardware","title":"Hardware","text":"<p>[More Information Needed: hardware requirements]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#software","title":"Software","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#citation","title":"Citation","text":"<p>BibTeX:</p> <p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#acknowledgements","title":"Acknowledgements","text":"<p>This work was supported by the Imageomics Institute, which is funded by the US National Science Foundation's Harnessing the Data Revolution (HDR) program under Award #2118240 (Imageomics: A New Frontier of Biological Information Powered by Knowledge-Guided Machine Learning). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#glossary","title":"Glossary","text":"","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#more-information","title":"More Information","text":"","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#model-card-authors","title":"Model Card Authors","text":"<p>[More Information Needed]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_Imageomics/#model-card-contact","title":"Model Card Contact","text":"<p>[More Information Needed--optional]</p>","tags":["biology","CV","images","animals"]},{"location":"wiki-guide/HF_ModelCard_Template_mkdocs/","title":"Model Card Template","text":""},{"location":"wiki-guide/HF_ModelCard_Template_mkdocs/#model-card-template","title":"Model Card Template","text":"<p>Below is the Model Card templates for Imageomics. You can download or copy the model card content and paste it into a new Markdown file to create a README for your model repo. </p> Imageomics Download template from GitHub <pre><code>---\nlicense: # See note below on choosing a license.\nlanguage:\n- en\nlibrary_name: # Allows for Inference API widget on sidebar of model card\ntags:\n- biology\n- CV\n- images\n- animals\ndatasets: # Adds link if on HF &amp; shows up on sidebar. Ex: imageomics/TreeOfLife-10M\nmetrics: # key list: https://hf.co/metrics\nmodel_description: # Add a short description (summary) of your model, this will render as part of the CardData object through the API, which can thus be used in applications such as the Imageomics Catalog\n---\n\n&lt;!--\n\nNOTE: Add more tags (your particular animal, type of model and use-case, etc.).\n\nAs with your GitHub Project repo, it is important to choose an appropriate license for your model. Alongside the appropriate stakeholders (eg., your PI, co-authors), select a license that is [Open Source Initiative](https://opensource.org/licenses) (OSI) compliant. You may also wish to consider adding a [RAIL license](https://www.licenses.ai/ai-licenses), which addresses responsible use.\nFor more information on how to choose a license and why it matters, see [Choose A License](https://choosealicense.com) and [A Quick Guide to Software Licensing for the Scientist-Programmer](https://doi.org/10.1371/journal.pcbi.1002598) by A. Morin, et al.\nSee the [Imageomics policy for licensing](https://imageomics.github.io/Imageomics-guide/wiki-guide/Digital-products-release-licensing-policy/) for more information.\n\nLicense tags (for the `yaml` above) can be found [here](https://hf.co/docs/hub/repositories-licenses).\n\nSee more options for the above information by clicking \"edit model card\" on your repo.\n\nFill in as much information as you can at each location that says \"More information needed\".\n--&gt;\n\n\n&lt;!--\nImage with caption (jpg or png):\n|![Figure #](https://huggingface.co/imageomics/&lt;model-repo&gt;/resolve/main/&lt;filepath&gt;)|\n|:--|\n|**Figure #.** [Image of &lt;&gt;](https://huggingface.co/imageomics/&lt;model-repo&gt;/raw/main/&lt;filepath&gt;) &lt;caption description&gt;.|\n--&gt;\n\n&lt;!--\nNotes on styling:\n\nTo render LaTex in your README, wrap the code in `\\\\(` and `\\\\)`. Example: \\\\(\\frac{1}{2}\\\\)\n\nEscape underscores (\"_\") with a \"\\\". Example: image\\_RGB\n--&gt;\n\n# Model Card for [Model Name]\n\n&lt;!-- Provide a quick summary of what the model is/does. \n\nThis model card aims to be a base template for new models. It has been generated using [this raw template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md?plain=1), and further altered to suit Imageomics Institute needs. --&gt;\n\n## Model Details\n\n### Model Description\n\n&lt;!-- Provide a longer summary of what this model is. --&gt;\n\n- **Developed by:** [More Information Needed]\n- **Model type:** [More Information Needed]\n- **Language(s) (NLP):** [More Information Needed]\n- **License:** [More Information Needed -- choose a license (see above notes)]\n- **Fine-tuned from model:** [More Information Needed]\n\n### Model Sources\n\n&lt;!-- Provide the basic links for the model. --&gt;\n\n- **Repository:** [Project Repo]\n- **Paper:** [More Information Needed--optional]\n- **Demo:** [More Information Needed--encouraged]\n\n## Uses\n\n&lt;!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. --&gt;\n\n### Direct Use\n\n&lt;!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. --&gt;\n\n[More Information Needed]\n\n### Downstream Use\n\n&lt;!-- [optional] This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app --&gt;\n\n[More Information Needed]\n\n### Out-of-Scope Use\n\n&lt;!-- This section addresses misuse, malicious use, and uses that the model will not work well for. --&gt;\n\n[More Information Needed]\n\n## Bias, Risks, and Limitations\n\n&lt;!-- This section is meant to convey both technical and sociotechnical limitations. --&gt;\n\n[More Information Needed]\n\n### Recommendations\n\n&lt;!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. --&gt;\n\nUsers (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.\n\n## How to Get Started with the Model\n\nUse the code below to get started with the model.\n\n&lt;!-- Put code here or links to files to run. Set up code blocks like this:\n```\u200b\n&lt;code here&gt;\n```\u200b\n--&gt;\n\n[More Information Needed]\n\n## Training Details\n\n### Training Data\n\n&lt;!-- This should link to a Dataset Card where possible, otherwise link to the original source with more info. \nProvide a basic overview of the training data and documentation related to data pre-processing or additional filtering. --&gt;\n\n[More Information Needed]\n\n### Training Procedure \n\n&lt;!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. --&gt;\n\n#### Preprocessing\n\n[More Information Needed--encouraged]\n\n\n#### Training Hyperparameters\n\n- **Training regime:** [More Information Needed] &lt;!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision --&gt;\n\n#### Speeds, Sizes, Times \n\n&lt;!-- [optional] This section provides information about throughput, start/end time, checkpoint size if relevant, etc. --&gt;\n\n[More Information Needed]\n\n## Evaluation\n\n&lt;!-- This section describes the evaluation protocols and provides the results. --&gt;\n\n[More Information Needed]\n\n### Testing Data, Factors &amp; Metrics\n\n#### Testing Data\n\n&lt;!-- This should link to a Dataset Card if possible, otherwise link to the original source with more info.\nProvide a basic overview of the test data and documentation related to any data pre-processing or additional filtering. --&gt;\n\n[More Information Needed]\n\n#### Factors\n\n&lt;!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. --&gt;\n\n[More Information Needed]\n\n#### Metrics\n\n&lt;!-- These are the evaluation metrics being used, ideally with a description of why. --&gt;\n\n[More Information Needed]\n\n### Results\n\n[More Information Needed]\n\n#### Summary\n\n[More Information Needed]\n\n## Model Examination\n\n&lt;!-- [optional] Relevant interpretability work for the model goes here --&gt;\n\n[More Information Needed]\n\n## Environmental Impact\n\n&lt;!-- \nIt would be great to try to include this.\n\nTotal emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly --&gt;\n\nCarbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://doi.org/10.48550/arXiv.1910.09700).\n\n- **Hardware Type:** [More Information Needed]\n- **Hours used:** [More Information Needed]\n- **Cloud Provider:** [More Information Needed]\n- **Compute Region:** [More Information Needed]\n- **Carbon Emitted:** [More Information Needed]\n\n## Technical Specifications \n[More Information Needed--optional]\n\n### Model Architecture and Objective\n\n[More Information Needed]\n\n### Compute Infrastructure\n\n[More Information Needed]\n\n#### Hardware\n\n[More Information Needed: hardware requirements]\n\n#### Software\n\n[More Information Needed]\n\n## Citation\n\n&lt;!-- If there is a paper introducing the model, the Bibtex information for that should go in this section. \n\nSee notes at top of file about selecting a license. \nIf you choose CC0: This model is dedicated to the public domain for the benefit of scientific pursuits. We ask that you cite the model and journal paper using the below citations if you make use of it in your research.\n\n--&gt;\n\n**BibTeX:**\n\n[More Information Needed]\n&lt;!--\nReplace \"&lt;&gt;\"s with your info:\n\nIf you use our model in your work, please cite the model and associated paper.\n\n**Model**\n```\u200b\n@software{&lt;ref_code&gt;,\n  author = {&lt;author1 and author2&gt;},\n  doi = {&lt;doi once generated&gt;},\n  title = {&lt;title&gt;},\n  version = {&lt;version#&gt;},\n  year = {&lt;year&gt;},\n  url = {https://huggingface.co/imageomics/&lt;model_name&gt;}\n}\n```\u200b\n\n-for an associated paper:\n**Paper**\n```\u200b\n@article{&lt;ref_code&gt;,\n  title    = {&lt;title&gt;},\n  author   = {&lt;author1 and author2&gt;},\n  journal  = {&lt;journal_name&gt;},\n  year     =  &lt;year&gt;,\n  url      = {&lt;DOI_URL&gt;},\n  doi      = {&lt;DOI&gt;}\n}\n```\u200b\n--&gt;\n\n\n## Acknowledgements\n\nThis work was supported by the [Imageomics Institute](https://imageomics.org), which is funded by the US National Science Foundation's Harnessing the Data Revolution (HDR) program under [Award #2118240](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2118240) (Imageomics: A New Frontier of Biological Information Powered by Knowledge-Guided Machine Learning). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.\n\n## Glossary \n\n&lt;!-- [optional] If relevant, include terms and calculations in this section that can help readers understand the model or model card. --&gt;\n\n## More Information \n\n&lt;!-- [optional] Any other relevant information that doesn't fit elsewhere. --&gt;\n\n## Model Card Authors\n\n[More Information Needed]\n\n## Model Card Contact\n\n[More Information Needed--optional]\n&lt;!-- Could include who to contact with questions, but this is also what the \"Discussions\" tab is for. --&gt;\n</code></pre>"},{"location":"wiki-guide/Handling-API-Keys/","title":"Handling API Keys","text":""},{"location":"wiki-guide/Handling-API-Keys/#handling-api-keys","title":"Handling API Keys","text":"<p>If you are using a web service with API keys, there are a few things to keep in mind. The key to key storage is that the process must meet the following requirements:</p> <ul> <li>Not hard-coded into your code</li> <li>Not visible in version-control</li> <li>Convenient to use</li> <li>Convenient to change if needed</li> <li>Unique for different environments</li> </ul>"},{"location":"wiki-guide/Handling-API-Keys/#key-storage","title":"Key Storage","text":"<p>Our recommended way of storing and using API is within <code>.env</code> (dotenv) files.</p> <p>A <code>.env</code> file is a simple text file that stores key-value pairs that set local environment variables. Its contents would look something like the following:</p> <pre><code>RESOURCE_API_KEY=your_api_key\n</code></pre> <p>For instance, if your API key for OpenAI is <code>sk-AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz</code>, you would put the following in your <code>.env</code> file.</p> <pre><code>OPENAI_API_KEY=sk-AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz\n</code></pre> <ul> <li>Ensure <code>.env</code> is added to your <code>.gitignore</code> file. The <code>.env</code> should not be published in a remote repository; it should be for your eyes only.</li> <li>Store the <code>.env</code> file in the root directory for your project.</li> <li>Backup the <code>.env</code> or key in a secure location. A free personal account with Bitwarden is an excellent option for this.</li> <li>If you notice the key or the <code>.env</code> file has been published somewhere public for any length of time, it must be changed immediately.</li> </ul> <p>Note</p> <p>The <code>.env</code> file is a simple text file, so you can use any text editor to create and edit it.</p>"},{"location":"wiki-guide/Handling-API-Keys/#key-usage","title":"Key Usage","text":"<p>If you are using Python, the <code>dotenv</code> package will enable to use this approach. First, install with pip or conda. In your work, the following will get you access to your API key as a Python variable <code>RESOURCE_API_KEY</code> (you may name it whatever you like; the Python variable may be different from the environment variable):</p> <pre><code>import os\nfrom dotenv import load_dotenv\n\nload_dotenv(\"relative/path/to/your/.env\")\n\nRESOURCE_API_KEY = os.getenv(\"RESOURCE_API_KEY\")\n</code></pre>"},{"location":"wiki-guide/Handling-API-Keys/#keys-for-a-shared-resource","title":"Keys for a Shared Resource","text":"<p>If you are part of a group with access to the same API:</p> <ul> <li>Create a unique API key for each application you use and for each environment you work in.</li> <li>Avoid sharing API keys with other users or between different applications/scripts.</li> </ul>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/","title":"Helpful Tools","text":""},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#helpful-tools-for-your-workflow","title":"Helpful Tools for your Workflow","text":"<p>This page is dedicated to tools that can facilitate or improve project workflows. There are many available options to solve most of these challenges; these suggestions are based on tools used regularly within our community. If there's something you use regularly that you think should be on this list, please suggest it!</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#better-version-control-for-notebooks","title":"Better Version Control for Notebooks","text":"<p>When working with Notebooks that may be re-run without changes to code, it's particularly hard in a collaborative setting to keep track of these changes\u2014or lack thereof. Jupytext and marimo are a couple of useful tools to address this challenge and improve the Notebook experience.</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#jupytext","title":"Jupytext","text":"<p>If you use Jupyter Notebooks in your project (as many of us do), you may want to consider adding Jupytext to your repertoire. mwouts/jupytext allows you to pair a Jupyter Notebook to a <code>.py</code> (or <code>.md</code>) file so that <code>git</code> renders clearer and more informative diffs, showing only the code and markdown cells that have been updated between commits. This makes it easier to see the differences between versions as you work through your project. For instance, if you re-ran your notebook with just a new random seed, the diff in the commit would show that without reproducing the whole thing, and you could go look at the output in the notebook.</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#how-it-works","title":"How it Works","text":"<p>Notebooks can be paired individually, or you can set a global config in your notebooks folder to generate a pairing automatically. Unfortunately, this automated pairing only works if you use Jupyter Lab (i.e., run notebooks through the terminal), not if you work in VS Code or other IDEs. Manual pairing code is given below.</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#jupytext-commands-in-terminal-for-vs-code","title":"Jupytext commands in terminal for VS Code","text":"<pre><code>jupytext --set-formats ipynb,py:percent &lt;notebook-name&gt;.ipynb  # Pair a notebook to a py script\njupytext --sync &lt;notebook-name&gt;.ipynb             # Sync the two representations\n</code></pre>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#but-wait-theres-another-way-to-automate-it","title":"But wait! ...There's another way to automate it!","text":"<p>There is a jupytext pre-commit hook that can be used to sync your paired files automatically when updating your GitHub repo. To learn more about pre-commit hooks in general, see the git docs on pre-commit hooks.</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#marimo","title":"Marimo","text":"<p>marimo functions similarly to a Jupyter Notebook, but has many built-in reproducibility and error-avoidance features, including the fact that it saves as a Python program (similar to the paired file created by Jupytext). See the summary in their README or explore the docs to get started.</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#formatting-and-linting","title":"Formatting and Linting","text":"<p>Have you found yourself saying, \"I just need to clean up my code first\"? Make this easier, and do it as you go, with linters! Additionally, formatting can impact code consistency and readability, while altering display of Markdown and generally adding noise version control diffs. Ruff and markdownlint are two tools designed to resolve this challenge, for Python and Markdown, respectively.</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#ruff","title":"Ruff","text":"<p>Fast Python formatter and linter. You can install astral-sh/ruff with\u00a0<code>pip install ruff</code> or <code>conda install ruff</code>\u00a0in your virtual/conda environment. They also have extensions for VS Code and other editors supporting LSP.</p> <p>To format a file, run:</p> <pre><code>ruff format &lt;path/to/file&gt;\n</code></pre> <p>and to lint it run</p> <pre><code>ruff check &lt;path/to/file&gt;\n</code></pre> <p>Ruff can also be set up as part of a pre-commit hook or GitHub Workflow. See their Usage section for more information.</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#markdownlint","title":"Markdownlint","text":"<p>Fast Markdown formatter and linter. We use the DavidAnson/markdownlint package for this site; see instructions and example in the linting section of our contributing guidelines. It is flexible in configuration and allows for simple checking or even fixing straight-forward formatting issues.</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#fair-data-access-and-validation","title":"FAIR Data Access and Validation","text":"<p>Don't add to the reproducibility crisis! Are you using existing data accessed through URLs and need to ensure consistency for re-use? Do you have a folder of images with all their metadata documented through their filenames? Cautious Robot and Sum Buddy are here to help.</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#cautious-robot","title":"Cautious Robot","text":"<p>Simple image from CSV downloader. The Imageomics/cautious-robot package provides a FAIR and Reproducible method for downloading a collection of images from URLs.</p> <ul> <li>Configurable wait time and max attempts for retry.</li> <li>Names images by given column with unique values.</li> <li>Logs all successful responses and errors for review after download.</li> <li>Uses sum-buddy to record checksums of all downloaded images.</li> <li>Performs minimal check that the number of expected images matches the number sum-buddy counts.</li> </ul> <p>Optional features:</p> <ul> <li>Organize images into subfolders based on any column in CSV.</li> <li>Create square images for modeling:<ul> <li>Organizes images in a second directory (same format) with copies of images in specified size.</li> </ul> </li> <li>Buddy-check: verifies all expected images downloaded intact (compares given checksums with sum-buddy output).</li> </ul>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#sample-command","title":"Sample Command","text":"<p>Given a CSV (<code>example.csv</code>) with a list of image URLs in a <code>file_url</code> column with <code>filename</code> providing unique IDs for each image, the following snippet will download these into an <code>example_images/</code> directory and validate the contents with provided MD5 hashes from the <code>md5</code> column of the CSV.</p> <pre><code>cautious-robot --input-file example.csv --output-dir example_images -v \"md5\"\n</code></pre> <p>To download larger (10-100M image scale), more distributed datasets, to HPC systems please see Imageomics/distributed-downloader.</p>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#sum-buddy","title":"Sum Buddy","text":"<p>Simple and flexible checksum calculator, from a single file to an entire directory. The Imageomics/sum-buddy package provides a FAIR and Reproducible method for duplicate file identification, efficient metadata generation, and general file integrity and validation support.</p> <ul> <li>Input: Folder with things to checksum.</li> <li>Output: CSV or printout of filepaths, filenames, and checksums.</li> <li>Options:<ul> <li>Ignore subfolders and patterns,</li> <li>Hash algorithm to use,</li> <li>Avoid hidden files and directories.</li> </ul> </li> <li>Usage: Run as a CLI or with exposed Python methods.</li> </ul>"},{"location":"wiki-guide/Helpful-Tools-for-your-Workflow/#sample-use-case","title":"Sample Use Case","text":"<p>Given a collection of images, e.g., in an <code>images/</code> directory, with no accompanying metadata, quickly generate a metadata file listing the filepaths, filenames, and checksums of all images contained in the folder. Note the option to include an \"ignore file\". This operates similarly to a <code>.gitignore</code>, allowing one to avoid inclusion of particular files or file types. In this case, let's assume there may be some <code>.doc</code> or similar included with the images. Hidden files and directories (e.g., <code>.DS_Store</code>) are ignored by default.</p> <pre><code>sum-buddy --output-file metadata.csv --ignore-file .sbignore images/\n</code></pre> <p>The added benefit to this method of metadata CSV generation is the ability to quickly and easily check for duplicate images within a collection. See our data training repo to learn more about this subject.</p>"},{"location":"wiki-guide/Hugging-Face-Repo-Guide/","title":"Repo Guide","text":""},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#hugging-face-repo-guide","title":"Hugging Face Repo Guide","text":"<p>Need a repository to store your data or model? You've come to the right place! Below we have compiled guidance on conventions and best practices for maintaining a shared (or shareable) Hugging Face repository of your work.</p>"},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#setting-up-a-new-organization-repository","title":"Setting up a New Organization Repository","text":""},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#standard-files","title":"Standard Files","text":"<p>For each repository, include the following files in the root directory as soon as possible; a license can (and should) be instantiated when you create a new repository, and the standard <code>.gitattributes</code> will be generated for you. On the Imageomics HF select <code>New</code> and pick which type of repository you need.</p> <ul> <li>README.md</li> <li>LICENSE.md</li> <li>.gitignore</li> <li>.gitattributes</li> </ul>"},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#readme","title":"README","text":"<p>The README.md file is generally referred to as either a Dataset or Model Card and is what everyone will notice first when they open your repository on Hugging Face. Choose the appropriate Imageomics-specific HF template (model or dataset) to get started. Be sure to include a brief description and as much information as possible at the beginning. You can update this file as you go, so don't remove the recommended sections prior to completion. The templates include descriptions of many fields, Imageomics grant information, citation formatting, and some notes on HF-flavored markdown to get you started.</p> <p>Once you've created your repo, populate your README (you can do this online by selecting \"Create Dataset/Model Card\" and pasting in the appropriate Imageomics HF template, then filling in your info). Editing your README in the browser allows you to preview the formatting of the file before committing changes.</p>"},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#license","title":"LICENSE","text":""},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#1-select-a-license","title":"1. Select a license","text":"<p>Alongside the appropriate stakeholders, select a license that is Open Source Initiative (OSI) compliant.</p> <p>Remember</p> <p>A public repository on Hugging Face with no license can be viewed and accessed by others, but unless the author associates a license, it is unclear what others are allowed to do with it legally. Adding an OSI license can help others feel comfortable building off your work!</p> <p>For more information on how to choose a license and why it matters, see Choose A License and A Quick Guide to Software Licensing for the Scientist-Programmer by A. Morin, et al.</p>"},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#2-add-licensemd-to-the-repository","title":"2. Add LICENSE.md to the repository","text":"<p>Once a license has been chosen (if not initialized with one), add the appropriate license label in the <code>yaml</code> portion of the README (the web UI generates a dropdown of recommendations under \"Edit dataset/model card\").</p>"},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#gitignore","title":"gitignore","text":"<p>As with GitHub, the <code>.gitignore</code> file is an important tool for maintaining a clean repository by ensuring that git will not track temp files of any and all your collaborators (no pesky <code>pycache</code> or <code>.DS_Store</code> files floating around).</p> <p>The same options for GitHub are usable here, and if you or anyone on your team uses a Mac (or if you intend to encourage outside collaboration on this repo), add</p> <pre><code># Mac system\n.DS_Store\n</code></pre> <p>at the end of the <code>.gitignore</code> file.</p>"},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#gitattributes","title":"gitattributes","text":"<p>The <code>.gitattributes</code> file determines file patterns to be tracked by <code>git LFS</code> (Git Large File Storage). The preset <code>gitattributes</code> file includes many binary file types, but you may need to add particular files if they get too large (eg., a large CSV, but do NOT store all CSV files with <code>git LFS</code>, just add the particular one or pattern). Pattern-matching can be done using <code>*</code>. You can either add the file (and appropriate pattern description) to the <code>.gitattributes</code> file, or add it in the command line:</p> <pre><code>git lfs track \"my-big-list.csv\"\n</code></pre> <p>Then add and commit the <code>.gitattributes</code> file as described below.</p>"},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#hugging-face-pull-requests-with-local-edits","title":"Hugging Face Pull Requests With Local Edits","text":"<p>Hugging Face also has a pull request (PR) feature, though the process is a bit different from GitHub.</p> <p>As with GitHub, you can interact through the web browser or a command line interface (eg., terminal on Mac). However, instead of the <code>create new branch</code> option, there is a <code>create new pull request</code> option. It is still preferable to avoid committing everything directly to main. To make further changes to the particular PR created on the browser, one must first clone the repo:</p> <pre><code>git clone &lt;repo-url&gt; \n</code></pre> <p>Then, navigate to that folder <code>cd &lt;repo-name&gt;</code>, and fetch the PR files:</p> <pre><code>git fetch origin refs/pr/&lt;PR#&gt;:pr/&lt;PR#&gt;\ngit checkout pr/&lt;PR#&gt;\n</code></pre> <p>You can then make your updates, add and commit them, then push those back to the remote. Note that the push is the one line that differs from GitHub and must be used each time:</p> <pre><code>git add &lt;changed files&gt;\ngit commit -m \"&lt;change&gt;\"\ngit push origin pr/&lt;PR#&gt;:refs/pr/&lt;PR#&gt;\n</code></pre> <p>For more information on Hugging Face Pull Requests and Discussions, see their documentation.</p>"},{"location":"wiki-guide/Hugging-Face-Repo-Guide/#templates-for-model-and-dataset-cards","title":"Templates for Model and Dataset Cards","text":"<p>See About Templates for guidelines on using templates for these important pieces of documentation.</p>"},{"location":"wiki-guide/Metadata-Checklist/","title":"Metadata Checklist","text":""},{"location":"wiki-guide/Metadata-Checklist/#metadata-checklist","title":"Metadata Checklist","text":"<p>When collecting or compiling new data, there are generally questions one is trying to answer. There are also often questions that will come up later\u2014whether for yourself or others interested in using your data.</p> <p>To improve both the Findability and Reusability of your data (ensuring FAIR principles) for yourself and others, be sure to note down the following information.</p> <p>This is not an exhaustive list.</p> <p>Be sure to include any other information that may be important to your particular project or field. For instance, see the Code, Data, and Model Checklists included in this section.</p>"},{"location":"wiki-guide/Metadata-Checklist/#checklist-for-metadata-to-record","title":"Checklist for Metadata to Record","text":"<ul> <li> Description: Summary of your data, for instance:<ul> <li>What are the contents of the data (images, text, type of animal)?</li> <li>Is it machine-ready?</li> <li>Where did it come from (Source)?</li> </ul> </li> <li> Data Sources: Machine-readable sources of the data (links or other files).</li> <li> License Information: This is part of retaining records of a data source (e.g., museum images, previous dataset). A record of licenses on the images must be retained to ensure they are respected. If dealing with CC licenses, please see this OSU Library CC best practices guide.</li> <li> Dataset Structure:<ul> <li>Organization of the full dataset (e.g., file structure).</li> <li>Feature information: Information available for each image, such as species and subspecies designations, location information, etc.</li> <li>Instance information: Image type (jpg, tiff, png), number of pixels per image, color space (RGB, UV), presence of scale or color indicators (ruler or ColorChecker), etc.</li> </ul> </li> <li> Processing Steps: List modifications performed (as they're done) and include links to the code used (this should be organized somewhere, like a GitHub repository).<ul> <li>Similarly, include any annotation process information.</li> </ul> </li> <li> Tasks: What could this dataset be used for (e.g., image classification, feature extraction, image segmentation, etc.).</li> <li> Curation Rationale: Why are you collecting and/or modifying this data?<ul> <li>This ties into the question of tasks it could be applied to, both to help maintain the group focus, and increase the likelihood others interested in answering similar questions will be able to find and use your data.</li> </ul> </li> <li> Author: The curator(s)/editor(s) of the data. Assumes sufficient modification of the data by you (and your team) or that you have collected it.<ul> <li>If thinking about publishing the data, add ORCID to all Authors; these can be looked up on orcid.org.</li> </ul> </li> <li> Related Publications: Any papers that are based on this dataset.</li> <li> Related Datasets: Provide links to any related datasets (may include previous/background research).</li> <li> Other References: Links to any related/background articles.</li> <li> Keywords/Tags: Terms one might search to find this dataset, e.g., type(s) of animals, type(s) of images, imbalanced (if not even distribution of species/subspecies/etc).<ul> <li>It helps to keep a running list.</li> </ul> </li> <li> Notes: Any other image/data information.</li> </ul> <p>Remember</p> <p>Datasets cannot be redistributed without this information. </p> <p>Pro tip</p> <p>Use the eye icon at the top of this page to access the source and copy the markdown for the checklist above into an issue on your GitHub Repo or Project so you can check the boxes as you add each.</p> <p>Questions, Comments, or Concerns?</p>"},{"location":"wiki-guide/Model-Checklist/","title":"Model Card Checklist","text":""},{"location":"wiki-guide/Model-Checklist/#model-card-checklist","title":"Model Card Checklist","text":"<p>Below is a checklist encompassing all sections of a model card. Review notes and guidance provided in the full model card template for more details.</p> <p>Pro tip</p> <p>Use the eye icon at the top of this page to access the source and copy the markdown for the checklist below into an issue on your GitHub Repo or Project so you can check the boxes as you add each element to your model card.</p>"},{"location":"wiki-guide/Model-Checklist/#general-information","title":"General Information","text":"<ul> <li> Model Name: Provide the name of the model.</li> <li> Model Summary: Provide a quick summary of what the model is/does</li> <li> License: Choose an appropriate license (e.g., <code>cc0-1.0</code>).</li> <li> Language(s): Specify the language(s) used (e.g., <code>en</code>).</li> <li> Tags: Include relevant tags (e.g., <code>biology</code>, <code>CV</code>, <code>images</code>, <code>animals</code>).</li> <li> Datasets: List datasets used for training, linking if hosted on Hugging Face. E.g.: imageomics/TreeOfLife-10M</li> <li> Metrics: Specify key evaluation metrics (refer to Hugging Face metrics list).</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#model-details","title":"Model Details","text":"<ul> <li> Detailed Summary: Provide a longer summary of what this model is.</li> <li> Developed by: List the developers.</li> <li> Model Type: Describe the model type.</li> <li> Fine-tuned from: Specify the base model if fine-tuned.</li> <li> Version: Indicate the model version.</li> <li> Repository: Provide the link to the project repository (GitHub).</li> <li> Paper: Link to any associated research papers (not expected at this point).</li> <li> Demo: Link to an interactive demo (if available).</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#uses","title":"Uses","text":"<ul> <li> Direct Use: Describe how the model can be used without fine-tuning or plugging into a larger ecosystem/app.</li> <li> Downstream Use: List potential fine-tuned applications for a task, or plugging into a larger ecosystem/app.</li> <li> Out-of-Scope Use: Indicate any misuse, malicious use, and uses that the model will not work well for.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#bias-risks-and-limitations","title":"Bias, Risks, and Limitations","text":"<ul> <li> Bias, Risks, and Limitations: Discuss potential biases and in the model, along with possible mitigations.</li> <li> Recommendations: Provide responsible usage recommendations with respect to the bias, risk, and technical limitations.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#getting-started","title":"Getting Started","text":"<ul> <li> Usage Instructions: Provide example code for using the model.</li> <li> Installation Guide: List dependencies and installation steps.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#training-details","title":"Training Details","text":"<ul> <li> Training Data: Describe the dataset used for training. This should link to a Dataset Card where possible, otherwise link to the original source with more info.</li> <li> Preprocessing: Detail data preprocessing techniques.</li> <li> Training Procedure: Describe the training approach.</li> <li> Training Hyperparameters: List key hyperparameters used.</li> <li> Speeds, Sizes, Times: Provide information about throughput, start/end time, checkpoint size if relevant, etc.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#evaluation","title":"Evaluation","text":"<p>This section describes the evaluation protocols and provides the results.</p> <ul> <li> Testing Data: Describe the dataset used for testing. This should link to a Dataset Card if possible, otherwise link to the original source with more info.</li> <li> Factors: Describe evaluation criteria (e.g., subpopulations, domains).</li> <li> Metrics: Specify evaluation metrics and reasoning.</li> <li> Results: Summarize model performance on testing data</li> <li> Benchmark Comparisons: Compare with existing baselines.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#model-examination","title":"Model Examination","text":"<ul> <li> Interpretability: Provide information on model explainability.</li> <li> Visualization: Include any relevant visualizations.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#environmental-impact","title":"Environmental Impact","text":"<ul> <li> Compute Region: Specify cloud provider and region.</li> <li> Hardware Type: List GPUs and CPUs used.</li> <li> Training Hours: Estimate the total training time.</li> <li> Carbon Emissions: Calculate emissions using the ML Impact calculator.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#technical-specifications","title":"Technical Specifications","text":"<ul> <li> Model Architecture: Provide a detailed architecture description and the choices behind its selection.</li> <li> Performance Metrics: List performance metrics and their significance.</li> <li> Model Size: Specify the model size in MB.</li> <li> Compute Requirements: List hardware and software requirements.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#licensing-and-citation","title":"Licensing and Citation","text":"<p>See discussion and references in the template, also remember the digital product release and licensing policy.</p> <ul> <li> License: Confirm licensing details.</li> <li> Citation: Provide a BibTeX citation for the model and associated paper.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#acknowledgements","title":"Acknowledgements","text":"<ul> <li> Funding and Support: List sources of funding and institutional support.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#glossary-optional","title":"Glossary (Optional)","text":"<ul> <li> Definitions: Provide explanations for technical terms.</li> </ul>"},{"location":"wiki-guide/Model-Checklist/#additional-information","title":"Additional Information","text":"<ul> <li> Notes: Include any other relevant details.</li> <li> Model Card Authors: List contributors to the model card.</li> <li> Model Card Contact: [OPTIONAL] We recommend people use HF discussions, but you may indicate a person to contact.</li> </ul> <p>Questions, Comments, or Concerns?</p>"},{"location":"wiki-guide/Technical-Infrastructure/","title":"Technical Infrastructure","text":""},{"location":"wiki-guide/Technical-Infrastructure/#compute-infrastructure-we-use","title":"Compute Infrastructure We Use","text":""},{"location":"wiki-guide/Technical-Infrastructure/#overview","title":"Overview","text":"<p>Overall Infrastructure Chart with system specifications and notes.</p> <ul> <li>The Ohio Supercomputing Center (OSC): Large compute resource accessible through <code>ssh</code> or OnDemand (web) platform.<ul> <li>Globus Endpoint \u2014 this is the preferred transfer method for collaborations, especially for large data.</li> <li>OnDemand page: info, login</li> <li>myOSC client portal: info, login</li> <li>OSC Storage Guidelines (internal): recommended usage patterns for each file system on OSC.</li> </ul> </li> <li>Imageomics dedicated GPU server: Internal server, hosts our CVAT instance.<ul> <li>Usage and access guide (internal)</li> <li>CVAT user guide</li> </ul> </li> <li>NSF ACCESS Accelerate Allocation: NCSA Delta GPU credits</li> <li>Amazon Web Services (AWS): Basic to extremely powerful, abundant (though finite) resources, high cost.<ul> <li>Used sparingly for urgent deadlines when other compute is not available (generally hasn't been available at those times either, though) or to host projects that cannot be hosted effectively through a Hugging Face Space.</li> <li>AWS usage guidelines (internal)</li> </ul> </li> </ul>"},{"location":"wiki-guide/Technical-Infrastructure/#other-compute-resources-weve-used-or-considered","title":"Other Compute Resources We've Used or Considered","text":"<ul> <li>OpenAI Researcher Access Program (internal info)</li> <li>NAIRR Pilot Program</li> </ul>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/","title":"Pull Request Guide","text":""},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#github-pull-request-pr-guide-overview","title":"GitHub Pull Request (PR) Guide Overview","text":"<p>This guide is divided into three essential sections to help you effectively manage pull requests in a collaborative project:</p> <ul> <li>Create a Pull Request: This section explains how to properly prepare and submit a pull request (PR) to ensure that your changes are well-documented, easy to review, and aligned with project goals.</li> <li>Review a Pull Request: Learn the best practices for providing constructive feedback, identifying potential issues, and ensuring code quality during the review process.</li> <li>Respond to a Pull Request Review: Understand how to address reviewer feedback, make necessary changes, and ensure your pull request meets the required standards for approval.</li> </ul> <p>By following these steps, you will contribute to a smooth and efficient workflow, ensuring collaboration and quality in your project.</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#1-create-a-pull-request","title":"1. Create a Pull Request","text":"<p>Before creating a pull request, first, please follow the GitHub Workflow to create and push your branch.</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#11-navigate-to-the-repositorys-main-page","title":"1.1 Navigate to the Repository's Main Page","text":"<p>On GitHub, go to the main page of the repository where you\u2019ve pushed your branch.</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#12-select-your-branch","title":"1.2 Select Your Branch","text":"<p>From the \"Branch\" menu, choose the branch that contains your changes (the one you just pushed).</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#13-click-compare-pull-request","title":"1.3 Click 'Compare &amp; pull request'","text":"<p>You\u2019ll see a button labeled Compare &amp; pull request. Click this to begin the process of creating a pull request for your changes.</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#14-add-title-and-description","title":"1.4 Add Title and Description","text":"<p>In the pull request form, type a descriptive title for your PR. Provide a detailed description of the changes you've made, why they are important, and any other relevant information.</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#15-choose-review-type","title":"1.5 Choose Review Type","text":"<ul> <li>If your pull request is ready for review, click Create Pull Request.</li> <li>If you want to create a draft version of the pull request for further work before it's ready for others to review, click the drop-down and select Create Draft Pull Request, then click Draft Pull Request.</li> </ul>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#2-review-a-pull-request","title":"2. Review a Pull Request","text":""},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#21-navigate-to-the-pull-requests-tab","title":"2.1 Navigate to the Pull requests tab","text":""},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#22-select-a-pull-request","title":"2.2 Select a Pull Request","text":"<p>In the list of pull requests, click the pull request that you'd like to review.</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#23-review-changes","title":"2.3 Review Changes","text":"<p>In the pull request page, click Files changed so as to see the changes.</p> <p></p> <p>2.3.1 by clicking , you can choose the unified or split view.</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#24-add-comments-or-suggestions","title":"2.4 Add Comments or Suggestions","text":"<p>When hovering over the lines of code, you can click the blue comment icon to add your review comments.</p> <p></p> <p>2.4.1 If you'd like to add a comment on multiple lines, please click the line number of the first line you want to add comments and drag down to select a range of lines.</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#25-suggest-changes","title":"2.5 Suggest Changes","text":"<p>If you'd like to suggest a specific change to the lines, click , and then edit the text within the suggestion block.</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#26-comment-on-a-file","title":"2.6 Comment on a File","text":"<p>If you'd like to comment on a file, click  at the right top of the file, then add your comments.</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#27-mark-files-as-viewed","title":"2.7 Mark Files as Viewed","text":"<p>After you finished reviewing a file, you can mark it as viewed.</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#28-start-or-add-to-a-review","title":"2.8 Start or Add to a Review","text":"<p>When you're done, click Start a review. If you have already started a review, please click Add review comment.</p> <p>Notice</p> <p>All line comments are pending and only visible to you. You can edit the comments when needed. If you'd like to abandon your review, please go to in Review changes and click Abandon review</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#29-review-and-summarize-proposed-changes","title":"2.9 Review and Summarize Proposed Changes","text":"<p>Click Review changes, and then type comments to summarize your proposed changes.</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#210-select-review-type","title":"2.10 Select Review Type","text":"<ul> <li>Select Comment: Provide general feedback on the changes without explicitly approving or rejecting them.</li> <li>Select Approve: Indicate that you\u2019ve reviewed the changes and approve them for merging. A common comment for simple approvals is \"LGTM\" (Looks Good to Me).</li> <li>Select Request changes: Provide feedback indicating that revisions are needed before the changes can be approved.</li> </ul>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#211-click-submit-review","title":"2.11 Click Submit review","text":"<p>Current review round is done; this publishes your comments and suggestions. Then the PR can either be merged or updated (depending on approval or comments). We generally expect that whoever submits the PR will merge once all feedback has been incorporated or otherwise addressed.</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#3-respond-to-a-pull-request-review","title":"3. Respond to a Pull Request Review","text":""},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#31-navigate-to-the-repositorys-main-page","title":"3.1 Navigate to the Repository's Main Page","text":"<p>Navigate to your repository name, click Pull requests</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#32-incorporate-feedback-changes","title":"3.2 Incorporate Feedback Changes","text":"<p>After receiving feedback on your pull request, you can apply the changes in one of two ways: either by committing each change individually or by grouping several changes into a single commit. The method you choose depends on whether you prefer fine-grained control over the commit history or a more streamlined approach.</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#321-apply-a-change-in-its-own-commit","title":"3.2.1 Apply a change in its own commit","text":"<p>If you agree with at suggested change, qpply it by creating a separate commit for it. This approach helps keep your commit history clear and each change traceable.</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#322-add-multiple-suggestions-to-a-batch-of-changes","title":"3.2.2 Add multiple suggestions to a batch of changes","text":"<p>If you plan to include multiple changes in one commit, you can add suggestions to a batch. Once you've collected all the desired suggestions, click \"Commit suggestions\" to apply them in one go.</p> <p></p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#33-add-commit-message","title":"3.3 Add Commit Message","text":"<p>In the commit message field, enter a brief, descriptive message that clearly explains the changes made to the file(s).</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#34-click-commit-changes","title":"3.4 Click Commit changes","text":"<p>After entering your commit message, click the \"Commit changes\" button to finalize and save your modifications to the repository. This step ensures that your changes are recorded and can be reviewed or merged into the main codebase.</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#35-re-requesting-a-review","title":"3.5 Re-requesting a Review","text":"<p>If you\u2019ve addressed all the requested changes and your pull request requires further review, re-request a review by notifying the reviewers. This action prompts them to evaluate your updated code and provide feedback or approval.</p>"},{"location":"wiki-guide/The-GitHub-Pull-Request-Guide/#36-out-of-scope-suggestion","title":"3.6 Out-of-scope Suggestion","text":"<p>If the suggested change falls outside the scope of your pull request, create a new issue to address the feedback separately. Issues can be created directly from a PR comment.</p>"},{"location":"wiki-guide/The-GitHub-Workflow/","title":"Workflow","text":""},{"location":"wiki-guide/The-GitHub-Workflow/#github-workflow-guide","title":"GitHub Workflow Guide","text":"<p>Thank you for contributing!</p> <p>This document outlines guidelines for collaboratively contributing to a repository (repo). This workflow is ideal for when:</p> <ul> <li>You are a member of the Imageomics Institute and have write access to the repository you're contributing to.</li> <li>You have (or expect to have) multiple people contributing to the repository and want to keep contributions organized and all team members up-to-date on progress.</li> <li>You are working on a repository individually and want to keep contributions organized and log progress for your future self or others interested in seeing it.</li> </ul> <p>It follows a branch and pull request (PR) based workflow, which provides a controlled way to bring internal contributions together for those with write access to the repository (those without write access will need to fork the repository first before making contributions).</p> <p>Importantly, this workflow suggests that contributions are created through PRs rather than directly committing to or merging into the <code>main</code> branch.</p>"},{"location":"wiki-guide/The-GitHub-Workflow/#contribute-as-an-imageomics-member-with-write-access","title":"Contribute as an Imageomics member with write access","text":""},{"location":"wiki-guide/The-GitHub-Workflow/#1-clone-the-repo-to-your-machine","title":"1. Clone the repo to your machine","text":"<pre><code>git clone https://github.com/Imageomics/&lt;repo-name&gt;.git\ncd &lt;repo-name&gt;\n</code></pre>"},{"location":"wiki-guide/The-GitHub-Workflow/#2-create-a-new-branch","title":"2. Create a new branch","text":"<p>For example, if you want to add a feature to your code that simulates human vision, you could name the branch <code>feature/simulate-vision</code>.</p> <p>Pro tip</p> <p>Make a new branch for each PR scoped by the task, feature, or bug fix.</p> <pre><code>git branch feature/simulate-vision\ngit checkout feature/simulate-vision\n</code></pre> <p>or to create and switch to the new branch with a single command:</p> <pre><code>git checkout -b feature/simulate-vision\n</code></pre>"},{"location":"wiki-guide/The-GitHub-Workflow/#3-make-your-desired-changes","title":"3. Make your desired changes","text":"<p>For example, imagine you created three new files, each simulating a component of the human visual system: <code>retina.py</code>, <code>occipital.py</code>, and <code>visual_cortex.py</code>.</p>"},{"location":"wiki-guide/The-GitHub-Workflow/#4-stage-and-commit-changes-to-the-new-branch","title":"4. Stage and commit changes to the new branch","text":"<p>Commit frequently with each commit based on a logical self-contained change using descriptive commit messages.</p> <p>Pro tip</p> <ul> <li>Use imperative phrases beginning with words such as \"add\", \"update\", \"fix\", \"refactor\", \"remove\", \"improve\", ...</li> <li>Write a multi-line commit message with a short summary on the first line and a longer description if needed using <code>git commit -m \"Short summary\" -m \"Long description\"</code></li> </ul> <pre><code>git add retina.py occipital.py visual_cortex.py\ngit commit -m \"Implement the retina, occipital, and visual cortex components of the human visual system.\"\n</code></pre>"},{"location":"wiki-guide/The-GitHub-Workflow/#5-update-your-local-main-branch","title":"5. Update your local <code>main</code> branch","text":"<p>Ensure your local <code>main</code> branch is up-to-date with the remote to incorporate any changes other collaborators may have made.</p> <p>Pro tip</p> <p>If you're unsure what branch you should have checked out, remember that the branch being merged to or committed to should be the branch that is active. Check with <code>git branch</code> and look for <code>*</code> next to what's active.</p> <pre><code>git checkout main\ngit pull origin main\n</code></pre>"},{"location":"wiki-guide/The-GitHub-Workflow/#6-merge-changes-made-to-main-to-your-new-branch","title":"6. Merge changes made to <code>main</code> to your new branch","text":"<p>If updates were pulled into your local <code>main</code> branch, merge them into your new branch.</p> <pre><code>git checkout feature/simulate-vision\ngit merge main\n</code></pre>"},{"location":"wiki-guide/The-GitHub-Workflow/#7-push-your-new-branch-to-the-remote","title":"7. Push your new branch to the remote","text":"<p>This should contain any updates made by others as well as your new changes. The first time this is done for a branch, you will need to map the branch on your local 'downstream' repo to the corresponding branch on the remote 'upstream' repo. Following this, simply push.</p> <pre><code>git push --set-upstream origin HEAD # to auto-match upstream branch name to your current branch name\n# or\ngit push --set-upstream origin feature/simulate-vision # to specify the upstream branch name\n# or\ngit push # subsequent pushes for this branch once the remote tracking branch is set\n</code></pre>"},{"location":"wiki-guide/The-GitHub-Workflow/#8-make-changes-commit-and-push-with-this-branch-as-needed","title":"8. Make changes, commit, and push with this branch as needed","text":"<p>Repeat steps 3-7 until results are in a state suitable to merge with the project's <code>main</code> branch.</p>"},{"location":"wiki-guide/The-GitHub-Workflow/#9-open-a-pull-request","title":"9. Open a Pull Request","text":"<p>On the GitHub repo page, click the <code>Pull requests</code> tab, click the <code>New pull requests</code> button, select the new branch you pushed as the head branch and keep the base branch as <code>main</code> (where you want to merge your changes into). Click <code>Create pull request</code>.</p> <p>You can also set the PR to draft status for visibility and discussion of ongoing work.</p> <p>If you like doing everything from the command line, you can consider using the GitHub CLI for this step.</p> <p>Pro tip</p> <p>Keep PRs small and manageable for review; the scope should be focused on the task, feature, or bug fix associated with the branch.</p>"},{"location":"wiki-guide/The-GitHub-Workflow/#10-verify-the-repositories-and-branches-in-the-pr","title":"10. Verify the repositories and branches in the PR","text":"<p>Base Repository: The original repo you are contributing into.</p> <p>Head Repository: The repo you are contributing from, which is the same as the base repo unless you are working from a fork.</p> <p>Base Branch: <code>main</code> (or the branch you want to merge your changes into)</p> <p>Compare Branch: Your new branch with changes.</p>"},{"location":"wiki-guide/The-GitHub-Workflow/#11-title-and-describe-the-pr","title":"11. Title and describe the PR","text":"<p>Create a brief title describing the primary issue addressed in the PR. In the PR description, give a consolidated overview of the motivation for the change(s) and description of choices made. It should briefly summarize the holistic effect resulting from the component commits. Assign appropriate reviewer(s) and/or link the PR to a project.</p>"},{"location":"wiki-guide/The-GitHub-Workflow/#12-submit-the-pr","title":"12. Submit the PR","text":"<p>Click <code>Create pull request</code> to submit.</p> <p>For more details and guidance on the GitHub pull request process, please see our GitHub Pull Request Guide.</p>"},{"location":"wiki-guide/The-GitHub-Workflow/#13-clean-up-branches","title":"13. Clean up branches","text":"<p>After a branch is merged and a PR is closed, delete the branch from the remote and your local repository to keep things tidy.</p> <p>Pro tip</p> <p>Remember, a branch should exist to create a functional contribution to the repository through a PR, and once the function is merged in, the purpose of the branch is fulfilled. </p><pre><code>git checkout main # switch to the main branch before deleting another branch\ngit branch -d feature/simulate-vision # delete the local branch that was merged\ngit push origin --delete feature/simulate-vision # delete the remote branch that was merged\ngit fetch --prune # optionally, this removes any references to deleted remote branches\n</code></pre><p></p>"},{"location":"wiki-guide/The-GitHub-Workflow/#14-update-your-local-main-branch-before-starting-new-work","title":"14. Update your local main branch before starting new work","text":"<pre><code>git pull\n</code></pre> <p>And for a slightly abbreviated visual summary, the same workflow looks like this:</p> <p> (image credit: Jiayi Wu Cox Blog, noted source: Learning note from \u201cVersion Control with Git\u201d by Atlassian offered by Steve Byrnes on Coursera.)</p>"},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/","title":"Dataset Upload Guide","text":""},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#hugging-face-dataset-guide","title":"Hugging Face Dataset Guide","text":""},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#create-a-new-dataset-repository","title":"Create a New Dataset Repository","text":"<p>When creating a new dataset repository, you can make the dataset Public (accessible to anyone on the internet) or Private (accessible only to members of the organization).</p> <p></p>"},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#upload-a-dataset-with-the-web-interface","title":"Upload a Dataset with the Web Interface","text":"<p>In the Files and versions tab of the Dataset card, you can choose to add file in the hugging web interface.</p> <p></p>"},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#upload-a-dataset-with-hfapi","title":"Upload a Dataset with HfApi","text":"<pre><code>from huggingface_hub import login\n\n# Login with your personal token (find your tokens at: Settings/Access Tokens)\nlogin()\n\nfrom huggingface_hub import HfApi\napi = HfApi()\n\napi.upload_file (\n    path_or_fileobj = &lt;the local file path that you would like to upload&gt;,\n    path_in_repo = &lt;the path in the repo&gt;,\n    repo_id = &lt;ABC-Center/dataset name&gt;,\n    repo_type = 'dataset'\n)\n</code></pre>"},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#upload-a-dataset-with-git","title":"Upload a Dataset with Git","text":""},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#if-the-dataset-is-less-than-5gb","title":"If the Dataset is Less Than 5GB","text":"<p>Navigate to the folder for the repository:</p> <pre><code># Clone the repository\ngit clone https://huggingface.co/datasets/username/repo-name\n\n# Add, commit, and push the files\ngit add\ngit commit -m 'comments'\ngit push\n</code></pre>"},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#if-the-dataset-is-larger-than-5gb","title":"If the Dataset is Larger Than 5GB","text":""},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#install-git-lfs","title":"Install Git LFS","text":"<p>Follow instructions at https://git-lfs.com/</p>"},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#install-the-hugging-face-cli","title":"Install the Hugging Face CLI","text":"<pre><code>brew install huggingface-cli\npip install -U \"huggingface_hub[cli]\"\n</code></pre>"},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#enable-the-repository-to-upload-large-files","title":"Enable the repository to upload large files","text":"<pre><code>huggingface-cli lfs-enable-largefiles &lt;your local dataset&gt;\n</code></pre>"},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#initialize-git-lfs","title":"Initialize Git LFS","text":"<pre><code>git lfs install\n</code></pre>"},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#track-large-files-eg-csv-files","title":"Track large files (e.g., .csv files)","text":"<pre><code># Adds a line to .gitattributes, which Git uses to determine files managed by LFS\ngit lfs track \"*.csv\"  \ngit add .gitattributes\ngit commit -m \"Track large files with Git LFS\"\n</code></pre>"},{"location":"wiki-guide/The-Hugging-Face-Dataset-Upload-Guide/#add-commit-and-push-the-files","title":"Add, commit, and push the files","text":"<pre><code>git add \ngit commit -m 'comments'\ngit push\n</code></pre>"},{"location":"wiki-guide/The-Hugging-Face-Workflow/","title":"Workflow","text":""},{"location":"wiki-guide/The-Hugging-Face-Workflow/#hugging-face-workflow-guide","title":"Hugging Face Workflow Guide","text":""},{"location":"wiki-guide/The-Hugging-Face-Workflow/#hugging-face-pull-requests-with-local-edits","title":"Hugging Face Pull Requests With Local Edits","text":"<p>Hugging Face also has a pull request (PR) feature, though the process is a bit different from GitHub.</p> <p>As with GitHub, you can interact through the web browser or a command line interface (eg., terminal on Mac). However, instead of the <code>create new branch</code> option, there is a <code>create new pull request</code> option. It is still preferable to avoid committing everything directly to main. To make further changes to the particular PR created on the browser, one must first clone the repo:</p> <pre><code>git clone &lt;repo-url&gt; \n</code></pre> <p>Then, navigate to that folder <code>cd &lt;repo-name&gt;</code>, and fetch the PR files:</p> <pre><code>git fetch origin refs/pr/&lt;PR#&gt;:pr/&lt;PR#&gt;\ngit checkout pr/&lt;PR#&gt;\n</code></pre> <p>You can then make your updates, add and commit them, then push those back to the remote. Note that the push is the one line that differs from GitHub and must be used each time:</p> <pre><code>git add &lt;changed files&gt;\ngit commit -m \"&lt;change\"\ngit push origin pr/&lt;PR#&gt;:refs/pr/&lt;PR#&gt;\n</code></pre> <p>For more information on Hugging Face Pull Requests and Discussions, see their documentation.</p>"},{"location":"wiki-guide/The-Hugging-Face-Workflow/#contribute-as-an-imageomics-member-with-write-access","title":"Contribute as an Imageomics member with write access","text":"<p>The workflow on Hugging Face repositories should closely mirror that of GitHub repos (described in detail in the Github Workflow). However, Hugging Face repos function a little differently from GitHub\u2019s, so we will review the details relevant to those differences and refer back to the GitHub directions where necessary.</p> <p>Firstly, when making changes it is still best not to work on the main branch, but instead go through the pull request (PR) process. This process is a bit different on Hugging Face, as this is not their focus. Instead of initializing a new branch, we initialize a new PR. There are two ways of doing this, but both rely on the UI (web interface).</p> <ol> <li> <p>Make your change directly on the UI (upload a file, edit the dataset/model card, etc), BUT select \u201cOpen as a pull request to the <code>main</code> branch\u201d and write a descriptive commit message of your changes before pressing <code>commit</code>.</p> </li> <li> <p>Navigate to the \u201cCommunity\u201d tab, and click \u201cNew pull request\u201d</p> </li> </ol> Community tab with New pull request button New Pull Request Interface <p>Their instructions for \u201cfrom the website\u201d are out of date.</p> <p>You actually select \u201cAdd file\u201d, choose upload or create file, and you can upload any number of files (that are reasonable to include in a single commit) in a single commit, just select \u201cOpen as a pull request to the <code>main</code> branch\u201d, as described in #1.</p> <p>Now, to continue with the local branch method (if you intend to make multiple commits), give your PR an informative title and select \u201cCreate PR branch\u201d. This will take you to a new page with instructions on how to connect locally to the PR and send your updates back to the repo. If the repo is private, you will need to ensure your credentials are set before cloning/fetching.</p> <p></p> <p>Once you have made all of your changes, it is time to publish your branch. This is similar to initializing the PR on GitHub, in that you should:</p> <ul> <li>Provide a detailed description of what your PR does</li> <li>Tag one or two other people on the project to review it (<code>@hf-username please review</code>) From here, reviewers can add their comments and suggestions on your PR (Note: to see the files in the PR, click on the last commit, then select \u201cBrowse files\u201d)</li> </ul> <p>Now, if there are changes to be made based on reviewer suggestions, files can be edited as usual (pushing to the PR branch). Alternatively, if you are working from the web interface and need to add files (or edit files of a supported type), then click on \u201cfrom: refs/pr/#\u201d just below the title of your PR to view the copy of the repo on the PR branch (like looking at a different branch on GitHub). Files can be added or edited here too.</p> <p></p>"},{"location":"wiki-guide/Two-Repo-Problem/","title":"Two Repo Problem","text":""},{"location":"wiki-guide/Two-Repo-Problem/#two-repo-problem","title":"Two Repo Problem","text":"<p>When working on a research project often the code is kept private until a paper is published.</p> <p>In conflict with this is the need to have a public repo for following purposes:</p> <ul> <li>Host a website (via a <code>gh-pages</code> branch)</li> <li>Act as a placeholder for when the paper is published</li> <li>Share code from an earlier paper</li> </ul> <p>The typical approach is to have one public git repo and one private git repo.</p>"},{"location":"wiki-guide/Two-Repo-Problem/#merging-challenges","title":"Merging Challenges","text":"<p>Once code changes are complete in the private git repo moving them to the public git repo can be a problem. For instance, if the public git repo and the private git repo were created separately they will have unrelated histories.</p> <p>Common challenges when merging:</p> <ul> <li>Determining the correct git commands and steps to perform the merge</li> <li>Cleaning up many small commits into one or a few larger commits</li> <li>Merge conflicts - Files such as the README that may have diverged and result in merge conflicts</li> <li>Accidentally losing changes or duplicating changes</li> </ul>"},{"location":"wiki-guide/Two-Repo-Problem/#solutions","title":"Solutions","text":""},{"location":"wiki-guide/Two-Repo-Problem/#create-private-from-public-repo","title":"Create private from public repo","text":"<p>To ensure related histories, create the public repo and then create a private repo from it. The public repo will be created with a README file ensuring it has a commit. The private repo will be created without any extra files so it will have no commits.</p>"},{"location":"wiki-guide/Two-Repo-Problem/#1-create-public-repo","title":"1. Create Public Repo","text":"<p>First create a public repo with commits.</p> <p>Visit https://github.com/organizations/Imageomics/repositories/new</p> <ul> <li>Enter the public repo name</li> <li>Click the checkbox for <code>Add a README file</code></li> <li>Choose a license</li> <li>Select an appropriate <code>.gitignore</code> template</li> <li>Click <code>Create repository</code></li> </ul> <p>After this step you should see a repo with commits similar to the following:</p> <p></p>"},{"location":"wiki-guide/Two-Repo-Problem/#2-update-main-branch-of-public-repo","title":"2. Update Main Branch of Public Repo","text":"<p>Make changes to the README and <code>.gitignore</code> in the public repo such that no further changes will be needed until the private repo is merged.</p> <p>After this step you should see a repo with at least 2 commits similar to the following:</p> <p></p>"},{"location":"wiki-guide/Two-Repo-Problem/#3-add-branch-protections-to-public-repo","title":"3. Add Branch Protections to Public Repo","text":"<p>Once your repository is set up, only changes to the <code>gh-pages</code> branch are recommended; establish branch protections on both <code>main</code> and <code>gh-pages</code> that require review and approval (see When to think about branch protections for more information).</p> <p>There are two issues at play here:</p> <ol> <li>There is potential to introduce merge conflicts when bringing in the development repo to merge with the <code>main</code> branch if it has been changed. Hence, it is important that you avoid making changes to the <code>main</code> branch after spin-off.</li> <li>The <code>gh-pages</code> branch will generate the website for the publication. Hence, it is a \"published\" branch, requiring regular checks with protections like the <code>main</code> branch.</li> </ol>"},{"location":"wiki-guide/Two-Repo-Problem/#4-create-private-repo","title":"4. Create Private Repo","text":"<p>First create a private repo without commits.</p> <p>Visit https://github.com/organizations/Imageomics/repositories/new</p> <ul> <li>Enter the private repo name (ex: <code>&lt;public-repo&gt;-dev</code>)</li> <li>DO NOT check <code>Add a README file</code></li> <li>DO NOT Choose a license</li> <li>DO NOT select a .gitignore template</li> <li>Click <code>Create repository</code></li> </ul> <p>After this step you should see a repo without any commits with a box similar to the following:</p> <p></p>"},{"location":"wiki-guide/Two-Repo-Problem/#5-push-initial-changes-from-public-to-private","title":"5. Push initial changes from public to private","text":"<p>In the following example we will clone the private repo: <code>johnbradley/research-project-x-private</code>. And pull commits from the public repo: <code>johnbradley/research-project-x</code>.</p>"},{"location":"wiki-guide/Two-Repo-Problem/#5a-clone-private-repo","title":"5a. Clone Private Repo","text":"<pre><code>git clone git@github.com:johnbradley/research-project-x-private.git\n</code></pre> <p>Output will have a warning similar to the following:</p> <pre><code>Cloning into 'research-project-x-private'...\nwarning: You appear to have cloned an empty repository.\n</code></pre>"},{"location":"wiki-guide/Two-Repo-Problem/#5b-pull-commits-to-private-repo","title":"5b. Pull Commits to Private Repo","text":"<p>Switch to the private repo directory.</p> <pre><code>cd research-project-x-private\n</code></pre> <p>Add a new remote repo named <code>upstream</code> that points to the public GitHub repo.</p> <pre><code>git remote add upstream git@github.com:johnbradley/research-project-x.git\n</code></pre> <p>Pull commits from the public repo.</p> <pre><code>git pull upstream main\n</code></pre> <p>Note</p> <p>Running <code>git remote -v</code> will confirm where a standard git push (or git pull) will send (or receive) commits from.</p>"},{"location":"wiki-guide/Two-Repo-Problem/#5c-push-commits-to-private-repo-on-github","title":"5c. Push Commits to Private Repo on GitHub","text":"<pre><code>git push\n</code></pre> <p>After the above command you should be able to see commits in the private repo similar to the following:</p> <p></p> <p>Now you're ready to work on development in the private repo following the standard GitHub Workflow with the private repo as your remote.</p>"},{"location":"wiki-guide/Two-Repo-Problem/#merge-private-to-public","title":"Merge Private to Public","text":"<p>Once your changes are done on the private repo (i.e., when you're ready to make your project public) you can push the changes to the public repo.</p> <p>For this example the public repo will be at <code>johnbradley/research-project-x</code> and the private will be at <code>johnbradley/research-project-x-private</code>. A branch named <code>v1</code> will be created on the public repo with changes from the private repo.</p>"},{"location":"wiki-guide/Two-Repo-Problem/#create-a-branch-on-public-with-private-commits","title":"Create a branch on Public with Private commits","text":"<p>Clone the public repo, cd into the directory.</p> <pre><code>git clone git@github.com:johnbradley/research-project-x.git\ncd research-project-x\n</code></pre> <p>Ensure we are on the main branch and up to date with GitHub:</p> <pre><code>git checkout main\ngit pull\n</code></pre> <p>Create a branch named <code>v1</code>. Checkout the branch. This branch will hold the private repo changes.</p> <pre><code>git branch v1\ngit checkout v1\n</code></pre> <p>Add an upstream remote pointing at the private repo.</p> <pre><code>git remote add upstream git@github.com:johnbradley/research-project-x-private.git\n</code></pre> <p>Pull main branch changes from private repo into <code>v1</code> branch.</p> <pre><code>git pull upstream main\n</code></pre> <p>At this point you could rebase the commits to reduce them to meaningful commits. However, keep in mind that this would result in different commit histories on the public and private repos after pushing <code>v1</code>, which may impact the ability to use this strategy for a <code>v2</code>. It would be preferable to use this strategy in pull requests (PRs) during development.</p> <p>Push <code>v1</code> branch to the public repo.</p> <pre><code>git push --set-upstream origin v1\n</code></pre>"},{"location":"wiki-guide/Two-Repo-Problem/#next-steps","title":"Next Steps","text":"<p>At this point the main branch of the public repo should match the main branch of the private repo. Additional changes should be made only to the private repo, preferably using a branch. See Github-Workflow for more details. When you are ready to release a new version of the code in the private repo follow the Merge Private to Public instructions again using a new version branch name (eg. <code>v2</code>).</p>"},{"location":"wiki-guide/Two-Repo-Problem/#what-if-i-already-have-mismatched-repos","title":"What if I already have mismatched repos?","text":"<p>If you find yourself with two repositories that have misaligned histories, please read the following and reach out to the Imageomics Informatics Team so we can help.</p>"},{"location":"wiki-guide/Two-Repo-Problem/#resolving-mismatched-publicprivate-repos","title":"Resolving Mismatched Public/Private Repos","text":"<p>If you already have a public and private repo with unrelated histories resolving this can be challenging.</p> <p>Three approaches to resolve merging disparate public/private repos are documented here.</p> <ul> <li>Merge - use when the public and private repos contain only unrelated commits.</li> <li>Reset - use when all public repo commits can be deleted and replaced with private repo commits.</li> <li>Cherry Pick - use when the same commits exist in both repos with different hashes.</li> </ul>"},{"location":"wiki-guide/Two-Repo-Problem/#merge","title":"Merge","text":"<p>Merge commits from the <code>main</code> branch of the private repo into the <code>main</code> branch of the public repo.</p> <p>Warning</p> <p>If the repos have commits in common with different hashes this will result in merge conflicts and duplicated commits.</p> <p>Merge the main branch of the private repo with the main branch of the public repo. As far as maintaining history this is the safest approach. Often this approach results in merge conflicts. Merging conflicts can take time to manually resolve and is challenging to learn. The allow unrelated histories flag is necessary for this approach:</p> <pre><code>git merge --allow-unrelated-histories ...\n</code></pre>"},{"location":"wiki-guide/Two-Repo-Problem/#reset","title":"Reset","text":"<p>Replace all commits on the <code>main</code> branch of the public rep with commits from the <code>main</code> branch of the private repo.</p> <p>Danger</p> <p>This will destroy all history in the public repo main branch!</p> <p>This option is only safe to do when releasing the first version of a version on the public repo. After setting up the remote for upstream run a command similar to the following:</p> <pre><code>git reset --hard upstream/main\n</code></pre>"},{"location":"wiki-guide/Two-Repo-Problem/#cherry-pick","title":"Cherry Pick","text":"<p>This method is used when the same commits exist in both repos with different hashes. This requires finding which commits are in the private repo but not in the public repo.</p> <p>Warning</p> <p>If the commits you cherry-pick have commits in common with different hashes this will result in merge conflicts and duplicated commits.</p> <p>After fetching your upstream branch you can cherry pick a range of commits to add like so:</p> <pre><code>git cherry-pick &lt;start-commit-hash&gt;..&lt;end-commit-hash&gt;\n</code></pre>"},{"location":"wiki-guide/Virtual-Environments/","title":"Virtual Environments","text":""},{"location":"wiki-guide/Virtual-Environments/#managing-dependencies-and-environments","title":"Managing Dependencies and Environments","text":"<p>Recording dependencies and environment information is crucial for reproducibility and interoperability across different platforms. There are many options for this, and sometimes it is appropriate to use multiple within the same project.</p> <p>The goal is to make it as easy as possible for others (including your future self) to run the code.</p>"},{"location":"wiki-guide/Virtual-Environments/#conda-environments","title":"Conda Environments","text":"<p>The following example commands will get you set up with a Conda environment that can be tracked and shared.</p> <ul> <li>Install Miniconda.</li> <li>Create an environment: <code>conda create --name &lt;env-name&gt;</code></li> <li>Activate the environment: <code>conda activate &lt;env-name&gt;</code></li> <li>Install packages you need: <code>conda install -c conda-forge python=3.9 pandas matplotlib</code><ul> <li><code>-c conda-forge</code> specifies the channel to install from. (more information)</li> <li>You can specify the version of a package or omit this to get the latest available. (more information)</li> </ul> </li> <li>Once the needed packages are installed, export the environment to a file:</li> </ul> <pre><code>conda env export --no-builds --from-history | grep -v \"prefix\" &gt; environment.yml\n</code></pre> <p>Command breakdown</p> <ul> <li><code>--no-builds</code> and <code>--from-history</code> flags will cause the environment file to only specify the packages and versions that you manually installed. This may help with cross-platform compatibility by giving conda the flexibility to find compatible sub-dependencies on another system.</li> <li><code>| grep -v \"prefix\"</code> eliminates your system-specific environment storage location (what is called the <code>prefix</code>) from being added to the file</li> <li>If you want to add the actual package versions that were installed (if you did not specify during installation) to the <code>environment.yml</code> file, you can check those and copy-paste them in manually with <code>conda env list</code>.</li> <li>Don't forget to also add and track this new file with git!</li> <li>To install the dependencies somewhere else from this file, use <code>conda env create -f environment.yml</code>.</li> </ul>"},{"location":"wiki-guide/Virtual-Environments/#pip-virtual-environment","title":"Pip Virtual Environment","text":"<p>For virtual environments using <code>pip</code> to install packages (Python environments), use <code>python -m pip freeze</code> to print a list of packages (and their versions) installed in the environment.</p> <p>Command extension</p> <ul> <li><code>python -m pip freeze &gt; requirements.txt</code> will populate a <code>requirements.txt</code> file with all these packages and versions listed (eg., <code>pandas==2.0.1</code>).<ul> <li>Note: This will not give only minimum software requirements, but will also print all dependencies.</li> </ul> </li> <li>Install this machine-readable file with <code>pip install -r requirements.txt</code> when in the appropriate folder.</li> <li>For more information, see the pip documentation.</li> </ul>"},{"location":"wiki-guide/When-to-think-about-branch-protections/","title":"Branch Protections","text":""},{"location":"wiki-guide/When-to-think-about-branch-protections/#branch-protections","title":"Branch Protections","text":"<p>Is your project going public? Are you releasing a package or tool for general use? Then it's time to think about adding branch protections to <code>main</code>.</p>"},{"location":"wiki-guide/When-to-think-about-branch-protections/#what-are-branch-protections-and-why-do-we-need-them","title":"What are branch protections and why do we need them?","text":"<p>Branch protections are essentially a more formalized implementation of contributing guidelines for your repository. This could be anything from requiring a pull request before pushing or merging updates to <code>main</code>, to requiring approval by particular parties before merging a pull request. For more information on branch protections, see GitHub's docs on branch protection rules.</p> <p>Generally speaking, once the set of potential users exceeds that of repository developers (i.e., the repo goes public), it is wise to apply branch protections, especially for the <code>main</code> branch of the repo. The primary purpose is to--at a minimum--alert developers of changes prior to their implementation. For more information on potential branch protection rules, see GitHub's docs.</p>"},{"location":"wiki-guide/When-to-think-about-branch-protections/#how-to-implement-branch-protections","title":"How to Implement Branch Protections","text":"<p>From your repository, navigate to \"Settings\" and select \"Branches\" from the left toolbar. Provide the name of the branch you would like to protect, for instance <code>main</code>, and select the rules that you want applied to the branch. It is also possible to set the rules for branches matching a particular pattern (eg., type <code>*release*</code> to apply the rules to any branch containing the word <code>release</code>). You can also edit branch protection rules from this page.</p> <p>The example below shows the addition of branch protection rules for <code>main</code> that require a pull request and that it be approved prior to merging. It also will remove approval if other changes are added that require approval.</p>"},{"location":"wiki-guide/When-to-think-about-branch-protections/#example-branch-protection-rules-for-main","title":"Example Branch Protection Rules for <code>main</code>","text":""},{"location":"wiki-guide/When-to-think-about-branch-protections/#how-to-implement-rulesets-newer-version-of-branch-protections","title":"How to Implement Rulesets (Newer Version of Branch Protections)","text":"<p>From your repository, navigate to \"Settings\" and select \"Rules\" from the left toolbar. Click on \"New ruleset\" and select the type you wish to create (\"New branch ruleset\" is the ruleset equivalent to branch protections).</p> <p></p> <p>Here we have selected \"New branch ruleset\", and named it \"published-branch\", as we will be applying it to our publication branches (i.e., <code>main</code> and <code>gh-pages</code>). Be sure to select \"Active\" to enable the protections.</p> <p></p> <p>We choose to apply these to the default branch (<code>main</code> or <code>master</code>).</p> <p></p> <p>As with branch protections, it is also possible to set the rules for branches matching a particular pattern (eg., type <code>*release*</code> to apply the rules to any branch containing the word <code>release</code>). We will do this for <code>gh-pages</code>.</p> <p></p> <p>You can also edit branch rulesets from this page. The example below shows the addition of a branch ruleset that requires a pull request and that it be approved prior to merging. It also will remove approval if other changes are added that require approval. This is equivalent to the branch protection example given above.</p> <p>Note</p> <p>If your site is generated from <code>main</code>, you should create a separate ruleset for <code>gh-pages</code> that protects against deletions and force pushes (but does not require PRs). This is relevant when generating a site with tools like MkDocs.</p> <p></p>"},{"location":"wiki-guide/Why-use-the-Institute-GitHub/","title":"Why Use the Institute GitHub","text":""},{"location":"wiki-guide/Why-use-the-Institute-GitHub/#why-should-i-put-my-work-into-the-imageomics-github-org-you-ask","title":"\"Why should I put my work into the Imageomics GitHub org,\" you ask?","text":"<p>The Imageomics GitHub organization exists to facilitate collaboration and version control among team members working on projects within the institute and make them available to the research community. You are encouraged to take advantage of the benefits of using this GitHub organization for your institute projects!</p>"},{"location":"wiki-guide/Why-use-the-Institute-GitHub/#centralization","title":"Centralization","text":"<p>This is the main aspect that leads to other benefits. Whether you are running your code on your own computer, a GPU server, a supercomputing cluster, AWS, or the Matrix, maintaining a git repository of this code hosted on the institute GitHub org keeps everyone's work that is otherwise scattered around in a single place.  Some of the benefits derived from this are ...</p>"},{"location":"wiki-guide/Why-use-the-Institute-GitHub/#collaboration","title":"Collaboration","text":"<ul> <li>You know where your team's work is, and your team knows where your work is.</li> <li>Code is simpler to find, share, access, review, and manage.</li> <li>Access privileges can be granted and managed through Imageomics teams, which Institute staff can administer for you, rather than access having to be managed on a per-individual basis.</li> <li>Progress can be communicated readily, and help can be solicited when needed, including through teams.</li> </ul>"},{"location":"wiki-guide/Why-use-the-Institute-GitHub/#knowledge-sharing","title":"Knowledge Sharing","text":"<ul> <li>Projects documented by a well-written README file are much more accessible than combing through old Zoom recordings to find out or remember what someone else is working on.</li> <li>When new members join, they can get up-to-speed quickly.</li> <li>When members move on to new roles, their work is preserved and more easily continued and built upon.</li> <li>Good practices can diffuse through and between teams more quickly.</li> <li>These points enhance the research capacity and productivity of individuals as well as the overall institute.</li> </ul>"},{"location":"wiki-guide/Why-use-the-Institute-GitHub/#visibility-impact","title":"Visibility + Impact","text":"<ul> <li>Work hosted under the Imageomics GitHub organization is directly associated with and contributes to the institute's brand, showcasing the collective contributions of our teams and enhancing the visibility and impact of their work within the broader community.</li> <li>Your profile is featured alongside repositories you contribute to, providing opportunities for networking with those who find your work valuable.</li> </ul>"},{"location":"wiki-guide/Why-use-the-Institute-GitHub/#professional-development","title":"Professional Development","text":"<p>Despite its rough edges, the common standard for version control and code management is git. You'll get a competitive edge with experience using it on a team to collaborate.</p>"},{"location":"wiki-guide/Why-use-the-Institute-GitHub/#showcasing-your-work","title":"Showcasing Your Work","text":"<p>If you want your public work with Imageomics featured on your personal GitHub profile, you can make use of the GitHub pin feature to have public repositories of your choice appear at the top of your profile whether they belong to you through an organization or personally.</p>"},{"location":"wiki-guide/Why-use-the-Institute-GitHub/#flexibility","title":"Flexibility","text":"<p>While we encourage you to host your institute-related work on the Imageomics GitHub organization to maximize these benefits, we understand that there may be situations where other platforms or private repositories are more appropriate. These include:</p> <ul> <li>Personal projects or work not directly tied to the institute.</li> <li>Projects developed prior to joining the institute where transferring ownership might be complex or undesirable.</li> </ul> <p>We strongly encourage you to keep your institute-related work centrally organized in the Imageomics GitHub organization to maximize the benefits for you and your fellow researchers!</p>"},{"location":"wiki-guide/Why-use-the-Institute-Hugging-Face/","title":"Why Use the Institute Hugging Face","text":""},{"location":"wiki-guide/Why-use-the-Institute-Hugging-Face/#why-should-i-put-my-work-into-the-imageomics-hugging-face-org-you-ask","title":"\"Why should I put my work into the Imageomics Hugging Face org,\" you ask?","text":"<p>The Imageomics Hugging Face organization is a crucial resource for facilitating collaboration, sharing models, and enhancing the accessibility of our AI and machine learning projects. By utilizing the Imageomics Hugging Face organization, you can take full advantage of the following benefits:</p>"},{"location":"wiki-guide/Why-use-the-Institute-Hugging-Face/#centralization","title":"Centralization","text":"<p>Centralizing our models and datasets on the Imageomics Hugging Face organization ensures that all team members have a reliable source for the tools and resources they need. It helps to:</p> <ul> <li>Keep everyone's work in a unified location, making it easier to manage and access.</li> <li>Ensure consistency and reliability in the models and datasets used across different projects.</li> </ul>"},{"location":"wiki-guide/Why-use-the-Institute-Hugging-Face/#collaboration","title":"Collaboration","text":"<p>Hugging Face provides robust tools for collaborative development, making it easier to:</p> <ul> <li>Share models and datasets with your team and the wider research community.</li> <li>Contribute to and improve upon the work of others.</li> <li>Manage access through well-defined team structures, ensuring that the right people have the right permissions.</li> <li>Request and provide feedback through integrated commenting and discussion features.</li> </ul>"},{"location":"wiki-guide/Why-use-the-Institute-Hugging-Face/#knowledge-sharing","title":"Knowledge Sharing","text":"<p>By hosting models and datasets on Hugging Face, we enhance knowledge sharing within and beyond the institute. This includes:</p> <ul> <li>Providing clear documentation and usage examples, making it easier for new members to get up to speed.</li> <li>Facilitating the spread of best practices across teams and projects.</li> </ul>"},{"location":"wiki-guide/Why-use-the-Institute-Hugging-Face/#visibility-impact","title":"Visibility + Impact","text":"<p>Work hosted on the Imageomics Hugging Face organization benefits from increased visibility and impact:</p> <ul> <li>Models and datasets are directly associated with the Imageomics brand, showcasing our collective contributions.</li> <li>Your contributions are highlighted on your profile, enhancing your professional reputation and networking opportunities.</li> <li>High-quality, well-documented models and datasets can attract attention from the broader research community, leading to greater impact and potential collaborations.</li> </ul>"},{"location":"wiki-guide/Why-use-the-Institute-Hugging-Face/#professional-development","title":"Professional Development","text":"<p>Using Hugging Face provides valuable experience with tools and practices that are widely recognized in the AI and machine learning communities. This includes:</p> <ul> <li>Hands-on experience with state-of-the-art model hosting and deployment tools.</li> <li>Opportunities to learn and implement best practices in model management and version control.</li> </ul>"},{"location":"wiki-guide/Why-use-the-Institute-Hugging-Face/#showcasing-your-work","title":"Showcasing Your Work","text":"<p>Hugging Face offers several features to help you showcase your work:</p> <ul> <li>You can highlight your contributions by pinning repositories to your profile, making your most significant work easily accessible.</li> <li>Public models and datasets associated with the Imageomics organization can be featured on both your personal and the institute's profiles.</li> </ul>"},{"location":"wiki-guide/Why-use-the-Institute-Hugging-Face/#flexibility","title":"Flexibility","text":"<p>While we encourage you to host your institute-related work on the Imageomics Hugging Face organization to maximize these benefits, we understand that there may be situations where other platforms or private repositories are more appropriate. These include:</p> <ul> <li>Personal projects or work not directly tied to the institute.</li> <li>Projects developed prior to joining the institute where transferring ownership might be complex or undesirable.</li> </ul> <p>We strongly encourage you to leverage the Imageomics Hugging Face organization for your institute-related projects. This will help you and your fellow researchers maximize collaboration, knowledge sharing, and the overall impact of our collective work.</p>"}]}